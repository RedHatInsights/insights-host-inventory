apiVersion: template.openshift.io/v1
kind: Template
metadata:
  name: insights-host-inventory
objects:
- apiVersion: cloud.redhat.com/v1alpha1
  kind: ClowdApp
  metadata:
    name: ${CLOWDAPP_NAME}
  x-anchors:
    # Base podSpec for gunicorn-based deployments (service-reads/writes)
    gunicornPodSpec: &gunicornPodSpec
      image: ${IMAGE}:${IMAGE_TAG}
      args: [
        "gunicorn",
        "--workers=${GUNICORN_WORKERS}",
        "--threads=${GUNICORN_THREADS}",
        "--limit-request-field_size=${GUNICORN_REQUEST_FIELD_LIMIT}",
        "--limit-request-line=${GUNICORN_REQUEST_LINE_LIMIT}",
        "--worker-tmp-dir=/gunicorn",
        "--log-file=-",
        "--access-logfile=-",
        "-c",
        "gunicorn.conf.py",
        "-b",
        "0.0.0.0:8000",
        "-t",
        "60",
        "--worker-class=uvicorn.workers.UvicornWorker",
        "run:app"
      ]
      resources:
        limits:
          cpu: ${CPU_LIMIT_SERVICE}
          memory: ${MEMORY_LIMIT_SERVICE}
        requests:
          cpu: ${CPU_REQUEST_SERVICE}
          memory: ${MEMORY_REQUEST_SERVICE}
    # Base podSpec for message queue consumer deployments
    mqPodSpec: &mqPodSpec
      image: ${IMAGE}:${IMAGE_TAG}
      args: ["./inv_mq_service.py"]
      livenessProbe: &mqLivenessProbe
        failureThreshold: 3
        httpGet:
          path: /
          port: 9000
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      readinessProbe: &mqReadinessProbe
        tcpSocket:
          port: 9000
    # Probes for read services
    readProbes: &readProbes
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /health
          port: 8000
          scheme: HTTP
        periodSeconds: ${{INVENTORY_API_READS_LIVENESS_PROBE_PERIOD_SECONDS}}
        successThreshold: 1
        timeoutSeconds: ${{INVENTORY_API_READS_LIVENESS_PROBE_TIMEOUT_SECONDS}}
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /health
          port: 8000
          scheme: HTTP
        periodSeconds: ${{INVENTORY_API_READS_READINESS_PROBE_PERIOD_SECONDS}}
        successThreshold: 1
        timeoutSeconds: ${{INVENTORY_API_READS_READINESS_PROBE_TIMEOUT_SECONDS}}
    # Volume mounts and volumes for read-replica services
    readReplicaVolumeMounts: &readReplicaVolumeMounts
      - mountPath: /tmp/inventory/prometheus
        name: prometheus-volume
      - mountPath: /gunicorn
        name: gunicorn-worker-dir
      - mountPath: /etc/db/readreplica
        name: host-inventory-read-only-db
        readOnly: true
    # Common volumes for read-replica services
    readReplicaVolumes: &readReplicaVolumes
      - emptyDir: {}
        name: prometheus-volume
      - emptyDir:
          medium: Memory
        name: gunicorn-worker-dir
      - name: host-inventory-read-only-db
        secret:
          optional: true
          items:
          - key: db.host
            path: db_host
          - key: db.name
            path: db_name
          - key: db.password
            path: db_password
          - key: db.port
            path: db_port
          - key: db.user
            path: db_user
    # Common volumes for write services
    writeServiceVolumes: &writeServiceVolumes
      - emptyDir: {}
        name: prometheus-volume
      - emptyDir:
            medium: Memory
        name: gunicorn-worker-dir
    # Common volume mounts for write services
    writeServiceVolumeMounts: &writeServiceVolumeMounts
      - mountPath: /tmp/inventory/prometheus
        name: prometheus-volume
      - mountPath: /gunicorn
        name: gunicorn-worker-dir
    # Common token definition
    unleashToken: &unleashToken
      valueFrom:
        secretKeyRef:
          name: ${UNLEASH_SECRET_NAME}
          key: CLIENT_ACCESS_TOKEN
          optional: true
    # Common RBAC PSK secret reference
    rbacPsks: &rbacPsks
      valueFrom:
        secretKeyRef:
          key: psks.json
          name: rbac-psks
          optional: false
    # Common Kessel auth secret reference
    kesselClientId: &kesselClientId
      valueFrom:
        secretKeyRef:
          key: client-id
          name: kessel-auth-secret
          optional: true
    kesselClientSecret: &kesselClientSecret
      valueFrom:
        secretKeyRef:
          key: client-secret
          name: kessel-auth-secret
          optional: true
    # Common namespace field reference
    namespaceFieldRef: &namespaceFieldRef
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    # Common Segmentio write key
    segmentioWriteKey: &segmentioWriteKey
      valueFrom:
        secretKeyRef:
          name: segmentio
          key: WRITE_KEY
          optional: true
    # Base image and args for jobs
    jobPodSpecBase: &jobPodSpecBase
      image: ${IMAGE}:${IMAGE_TAG}
    # Init container that waits for DB migrations to complete
    # Used by deployments that need the DB schema to be up-to-date before starting
    migrationWaitInitContainer: &migrationWaitInitContainer
      - args: ["./wait_for_migrations.py"]
        inheritEnv: true
  spec:
    envName: ${ENV_NAME}
    featureFlags: true
    inMemoryDb: true
    testing:
      iqePlugin: host-inventory
    dependencies:
      - rbac
      - kessel-inventory
      - ingress
      - export-service
    deployments:
    - name: service
      podSpec:
        command:
        - nginx
        - -g
        - daemon off;
        env:
        - name: CLOWDER_ENABLED
          value: ${CLOWDER_ENABLED}
        - name: APP_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        image: registry.access.redhat.com/ubi9/nginx-124:latest
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /healthz
            port: web
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 20
          successThreshold: 1
          timeoutSeconds: 10
        readinessProbe:
          failureThreshold: 5
          httpGet:
            path: /healthz
            port: web
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 20
          successThreshold: 1
          timeoutSeconds: 10
        resources:
          limits:
            cpu: ${NGINX_CPU_LIMIT}
            memory: ${NGINX_MEMORY_LIMIT}
          requests:
            cpu: ${NGINX_CPU_REQUEST}
            memory: ${NGINX_MEMORY_REQUEST}
        volumeMounts:
        - mountPath: /etc/nginx
          name: api-nginx-conf
        volumes:
        - configMap:
            name: inventory-nginx-conf
          name: api-nginx-conf
      replicas: ${{NGINX_REPLICAS}}
      webServices:
        private:
          enabled: false
        public:
          apiPath: inventory
          enabled: true
    - name: service-reads
      replicas: ${{REPLICAS_SVC_READS}}
      webServices:
        public:
          enabled: true
      podSpec:
        <<: [ *gunicornPodSpec, *readProbes ]
        env:
          - name: APP_NAME
            value: ${APP_NAME}
          - name: PATH_PREFIX
            value: ${PATH_PREFIX}
          - name: CONSOLEDOT_HOSTNAME
            value: ${CONSOLEDOT_HOSTNAME}
          - name: INVENTORY_LEGACY_API_URL
            value: /r/insights/platform/inventory/v1
          - name: PROMETHEUS_MULTIPROC_DIR
            value: /tmp/inventory/prometheus
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: URLLIB3_LOG_LEVEL
            value: ${URLLIB3_LOG_LEVEL}
          - name: CONNEXION_LOG_LEVEL
            value: ${CONNEXION_LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: BYPASS_RBAC
            value: ${BYPASS_RBAC}
          - name: BYPASS_KESSEL
            value: ${BYPASS_KESSEL}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: CLOWDER_ENABLED
            value: "true"
          - name: INVENTORY_DB_STATEMENT_TIMEOUT
            value: "${INVENTORY_DB_STATEMENT_TIMEOUT}"
          - name: INVENTORY_DB_LOCK_TIMEOUT
            value: "${INVENTORY_DB_LOCK_TIMEOUT}"
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: INVENTORY_API_CACHE_TIMEOUT_SECONDS
            value: "${INVENTORY_API_CACHE_TIMEOUT_SECONDS}"
          - name: INVENTORY_API_CACHE_TYPE
            value: "${INVENTORY_API_CACHE_TYPE}"
          - name: INVENTORY_CACHE_INSIGHTS_CLIENT_SYSTEM_TIMEOUT_SEC
            value: "${INVENTORY_CACHE_INSIGHTS_CLIENT_SYSTEM_TIMEOUT_SEC}"
          - name: INVENTORY_CACHE_THREAD_POOL_MAX_WORKERS
            value: "${INVENTORY_CACHE_THREAD_POOL_MAX_WORKERS}"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - <<: *unleashToken
            name: UNLEASH_TOKEN
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
          - name: UNLEASH_REFRESH_INTERVAL
            value: ${UNLEASH_REFRESH_INTERVAL}
          - <<: *segmentioWriteKey
            name: SEGMENTIO_WRITE_KEY
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
          - name: INVENTORY_API_USE_READREPLICA
            value: "${INVENTORY_API_USE_READREPLICA}"
          - name: KESSEL_AUTH_CLIENT_ID
            <<: *kesselClientId
          - name: KESSEL_AUTH_CLIENT_SECRET
            <<: *kesselClientSecret
          - name: KESSEL_INSECURE
            value: ${KESSEL_INSECURE}
          - name: KESSEL_AUTH_ENABLED
            value: ${KESSEL_AUTH_ENABLED}
        volumeMounts: *readReplicaVolumeMounts
        volumes:
          - emptyDir: {}
            name: prometheus-volume
          - emptyDir:
              medium: Memory
            name: gunicorn-worker-dir
          - name: host-inventory-read-only-db
            secret:
              secretName: ${INVENTORY_API_READREPLICA_SECRET}
              optional: true
              items:
              - key: db.host
                path: db_host
              - key: db.name
                path: db_name
              - key: db.password
                path: db_password
              - key: db.port
                path: db_port
              - key: db.user
                path: db_user
    - name: service-secondary-reads
      replicas: ${{REPLICAS_SVC_SECONDARY_READS}}
      webServices:
        public:
          enabled: true
      podSpec:
        <<: [ *gunicornPodSpec, *readProbes ]
        env:
          - name: APP_NAME
            value: ${APP_NAME}
          - name: PATH_PREFIX
            value: ${PATH_PREFIX}
          - name: CONSOLEDOT_HOSTNAME
            value: ${CONSOLEDOT_HOSTNAME}
          - name: INVENTORY_LEGACY_API_URL
            value: /r/insights/platform/inventory/v1
          - name: PROMETHEUS_MULTIPROC_DIR
            value: /tmp/inventory/prometheus
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: URLLIB3_LOG_LEVEL
            value: ${URLLIB3_LOG_LEVEL}
          - name: CONNEXION_LOG_LEVEL
            value: ${CONNEXION_LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: BYPASS_RBAC
            value: ${BYPASS_RBAC}
          - name: BYPASS_KESSEL
            value: ${BYPASS_KESSEL}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: CLOWDER_ENABLED
            value: "true"
          - name: INVENTORY_DB_STATEMENT_TIMEOUT
            value: "${INVENTORY_DB_STATEMENT_TIMEOUT}"
          - name: INVENTORY_DB_LOCK_TIMEOUT
            value: "${INVENTORY_DB_LOCK_TIMEOUT}"
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: INVENTORY_API_CACHE_TIMEOUT_SECONDS
            value: "${INVENTORY_API_CACHE_TIMEOUT_SECONDS}"
          - name: INVENTORY_API_CACHE_TYPE
            value: "${INVENTORY_API_CACHE_TYPE}"
          - name: INVENTORY_CACHE_INSIGHTS_CLIENT_SYSTEM_TIMEOUT_SEC
            value: "${INVENTORY_CACHE_INSIGHTS_CLIENT_SYSTEM_TIMEOUT_SEC}"
          - name: INVENTORY_CACHE_THREAD_POOL_MAX_WORKERS
            value: "${INVENTORY_CACHE_THREAD_POOL_MAX_WORKERS}"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - <<: *unleashToken
            name: UNLEASH_TOKEN
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
          - name: UNLEASH_REFRESH_INTERVAL
            value: ${UNLEASH_REFRESH_INTERVAL}
          - <<: *segmentioWriteKey
            name: SEGMENTIO_WRITE_KEY
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
          - name: INVENTORY_API_USE_READREPLICA
            value: "${INVENTORY_API_USE_READREPLICA}"
          - name: KESSEL_AUTH_CLIENT_ID
            <<: *kesselClientId
          - name: KESSEL_AUTH_CLIENT_SECRET
            <<: *kesselClientSecret
          - name: KESSEL_INSECURE
            value: ${KESSEL_INSECURE}
          - name: KESSEL_AUTH_ENABLED
            value: ${KESSEL_AUTH_ENABLED}
        volumeMounts: *readReplicaVolumeMounts
        volumes:
          - emptyDir: {}
            name: prometheus-volume
          - emptyDir:
              medium: Memory
            name: gunicorn-worker-dir
          - name: host-inventory-read-only-db
            secret:
              secretName: ${INVENTORY_API_SECONDARY_READREPLICA_SECRET}
              optional: true
              items:
              - key: db.host
                path: db_host
              - key: db.name
                path: db_name
              - key: db.password
                path: db_password
              - key: db.port
                path: db_port
              - key: db.user
                path: db_user
    - name: service-writes
      replicas: ${{REPLICAS_SVC_WRITES}}
      webServices:
        public:
          enabled: true
      podSpec:
        <<: *gunicornPodSpec
        initContainers: *migrationWaitInitContainer
        env:
          - name: APP_NAME
            value: ${APP_NAME}
          - name: PATH_PREFIX
            value: ${PATH_PREFIX}
          - name: CONSOLEDOT_HOSTNAME
            value: ${CONSOLEDOT_HOSTNAME}
          - name: INVENTORY_LEGACY_API_URL
            value: /r/insights/platform/inventory/v1
          - name: PROMETHEUS_MULTIPROC_DIR
            value: /tmp/inventory/prometheus
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: URLLIB3_LOG_LEVEL
            value: ${URLLIB3_LOG_LEVEL}
          - name: CONNEXION_LOG_LEVEL
            value: ${CONNEXION_LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: BYPASS_RBAC
            value: ${BYPASS_RBAC}
          - name: BYPASS_KESSEL
            value: ${BYPASS_KESSEL}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: CLOWDER_ENABLED
            value: "true"
          - name: INVENTORY_DB_STATEMENT_TIMEOUT
            value: "${INVENTORY_DB_STATEMENT_TIMEOUT}"
          - name: INVENTORY_DB_LOCK_TIMEOUT
            value: "${INVENTORY_DB_LOCK_TIMEOUT}"
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: INVENTORY_API_CACHE_TIMEOUT_SECONDS
            value: "${INVENTORY_API_CACHE_TIMEOUT_SECONDS}"
          - name: INVENTORY_API_CACHE_TYPE
            value: "${INVENTORY_API_CACHE_TYPE}"
          - name: INVENTORY_CACHE_INSIGHTS_CLIENT_SYSTEM_TIMEOUT_SEC
            value: "${INVENTORY_CACHE_INSIGHTS_CLIENT_SYSTEM_TIMEOUT_SEC}"
          - name: INVENTORY_CACHE_THREAD_POOL_MAX_WORKERS
            value: "${INVENTORY_CACHE_THREAD_POOL_MAX_WORKERS}"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - <<: *unleashToken
            name: UNLEASH_TOKEN
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
          - name: UNLEASH_REFRESH_INTERVAL
            value: ${UNLEASH_REFRESH_INTERVAL}
          - <<: *segmentioWriteKey
            name: SEGMENTIO_WRITE_KEY
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
          - <<: *rbacPsks
            name: RBAC_PSKS
          - name: KESSEL_AUTH_CLIENT_ID
            <<: *kesselClientId
          - name: KESSEL_AUTH_CLIENT_SECRET
            <<: *kesselClientSecret
          - name: KESSEL_INSECURE
            value: ${KESSEL_INSECURE}
          - name: KESSEL_AUTH_ENABLED
            value: ${KESSEL_AUTH_ENABLED}
          - name: WAIT_FOR_MIGRATIONS_TIMEOUT_SECONDS
            value: ${WAIT_FOR_MIGRATIONS_TIMEOUT_SECONDS}
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /health
            port: 8000
            scheme: HTTP
          periodSeconds: ${{INVENTORY_API_WRITES_LIVENESS_PROBE_PERIOD_SECONDS}}
          successThreshold: 1
          timeoutSeconds: ${{INVENTORY_API_WRITES_LIVENESS_PROBE_TIMEOUT_SECONDS}}
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /health
            port: 8000
            scheme: HTTP
          periodSeconds: ${{INVENTORY_API_WRITES_READINESS_PROBE_PERIOD_SECONDS}}
          successThreshold: 1
          timeoutSeconds: ${{INVENTORY_API_WRITES_READINESS_PROBE_TIMEOUT_SECONDS}}
        volumeMounts: *writeServiceVolumeMounts
        volumes: *writeServiceVolumes
    - name: mq-pmin
      replicas: ${{REPLICAS_PMIN}}
      podSpec:
        <<: *mqPodSpec
        initContainers: *migrationWaitInitContainer
        env:
          - name: CONSOLEDOT_HOSTNAME
            value: ${CONSOLEDOT_HOSTNAME}
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: CONNEXION_LOG_LEVEL
            value: ${CONNEXION_LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: KAFKA_HOST_INGRESS_GROUP
            value: ${KAFKA_HOST_INGRESS_GROUP}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: KAFKA_SYSTEM_PROFILE_TOPIC
            value: ${KAFKA_SYSTEM_PROFILE_TOPIC}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - name: CLOWDER_ENABLED
            value: "true"
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: INVENTORY_API_CACHE_TIMEOUT_SECONDS
            value: "${INVENTORY_API_CACHE_TIMEOUT_SECONDS}"
          - name: INVENTORY_API_CACHE_TYPE
            value: "${INVENTORY_API_CACHE_TYPE}"
          - name: INVENTORY_CACHE_INSIGHTS_CLIENT_SYSTEM_TIMEOUT_SEC
            value: "${INVENTORY_CACHE_INSIGHTS_CLIENT_SYSTEM_TIMEOUT_SEC}"
          - name: INVENTORY_CACHE_THREAD_POOL_MAX_WORKERS
            value: "${INVENTORY_CACHE_THREAD_POOL_MAX_WORKERS}"
          - name: KAFKA_CONSUMER_SESSION_TIMEOUT_MS
            value: "${KAFKA_CONSUMER_SESSION_TIMEOUT_MS}"
          - name: KAFKA_CONSUMER_HEARTBEAT_INTERVAL_MS
            value: "${KAFKA_CONSUMER_HEARTBEAT_INTERVAL_MS}"
          - name: BYPASS_KESSEL
            value: ${BYPASS_KESSEL}
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - <<: *unleashToken
            name: UNLEASH_TOKEN
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
          - name: UNLEASH_REFRESH_INTERVAL
            value: ${UNLEASH_REFRESH_INTERVAL}
          - name: MQ_DB_BATCH_MAX_SECONDS
            value: ${MQ_DB_BATCH_MAX_SECONDS}
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory-mq-service
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: MQ_DB_BATCH_MAX_MESSAGES
            value: ${MQ_DB_BATCH_MAX_MESSAGES}
          - name: KAFKA_CONSUMER_TOPIC
            value: ${KAFKA_HOST_INGRESS_TOPIC}
          - name: KAFKA_HOST_INGRESS_TOPIC
            value: ${KAFKA_HOST_INGRESS_TOPIC}
          - <<: *rbacPsks
            name: RBAC_PSKS
          - name: WAIT_FOR_MIGRATIONS_TIMEOUT_SECONDS
            value: ${WAIT_FOR_MIGRATIONS_TIMEOUT_SECONDS}
        resources:
          limits:
            cpu: ${CPU_LIMIT_MQ_PMIN}
            memory: ${MEMORY_LIMIT_MQ_PMIN}
          requests:
            cpu: ${CPU_REQUEST_MQ_PMIN}
            memory: ${MEMORY_REQUEST_MQ_PMIN}
    - name: mq-p1
      replicas: ${{REPLICAS_P1}}
      podSpec:
        <<: *mqPodSpec
        initContainers: *migrationWaitInitContainer
        env:
          - name: CONSOLEDOT_HOSTNAME
            value: ${CONSOLEDOT_HOSTNAME}
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: CONNEXION_LOG_LEVEL
            value: ${CONNEXION_LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: KAFKA_HOST_INGRESS_GROUP
            value: ${KAFKA_HOST_INGRESS_GROUP}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: KAFKA_SYSTEM_PROFILE_TOPIC
            value: ${KAFKA_SYSTEM_PROFILE_TOPIC}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - name: BYPASS_KESSEL
            value: ${BYPASS_KESSEL}
          - name: CLOWDER_ENABLED
            value: "true"
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: INVENTORY_API_CACHE_TIMEOUT_SECONDS
            value: "${INVENTORY_API_CACHE_TIMEOUT_SECONDS}"
          - name: INVENTORY_API_CACHE_TYPE
            value: "${INVENTORY_API_CACHE_TYPE}"
          - name: INVENTORY_CACHE_INSIGHTS_CLIENT_SYSTEM_TIMEOUT_SEC
            value: "${INVENTORY_CACHE_INSIGHTS_CLIENT_SYSTEM_TIMEOUT_SEC}"
          - name: INVENTORY_CACHE_THREAD_POOL_MAX_WORKERS
            value: "${INVENTORY_CACHE_THREAD_POOL_MAX_WORKERS}"
          - name: KAFKA_CONSUMER_SESSION_TIMEOUT_MS
            value: "${KAFKA_CONSUMER_SESSION_TIMEOUT_MS}"
          - name: KAFKA_CONSUMER_HEARTBEAT_INTERVAL_MS
            value: "${KAFKA_CONSUMER_HEARTBEAT_INTERVAL_MS}"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - <<: *unleashToken
            name: UNLEASH_TOKEN
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
          - name: UNLEASH_REFRESH_INTERVAL
            value: ${UNLEASH_REFRESH_INTERVAL}
          - name: MQ_DB_BATCH_MAX_SECONDS
            value: ${MQ_DB_BATCH_MAX_SECONDS}
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
          - name: MIGRATION_MODE
            value: ${MIGRATION_MODE}
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory-mq-service
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: MQ_DB_BATCH_MAX_MESSAGES
            value: ${MQ_DB_BATCH_MAX_MESSAGES}
          - name: KAFKA_CONSUMER_TOPIC
            value: ${KAFKA_HOST_INGRESS_P1_TOPIC}
          - name: KAFKA_HOST_INGRESS_TOPIC
            value: ${KAFKA_HOST_INGRESS_P1_TOPIC}
          - name: HOSTS_TABLE_NUM_PARTITIONS
            value: ${HOSTS_TABLE_NUM_PARTITIONS}
          - <<: *rbacPsks
            name: RBAC_PSKS
        resources:
          limits:
            cpu: ${CPU_LIMIT_MQ_P1}
            memory: ${MEMORY_LIMIT_MQ_P1}
          requests:
            cpu: ${CPU_REQUEST_MQ_P1}
            memory: ${MEMORY_REQUEST_MQ_P1}
    - name: mq-sp
      replicas: ${{REPLICAS_SP}}
      podSpec:
        <<: *mqPodSpec
        initContainers: *migrationWaitInitContainer
        env:
          - name: CONSOLEDOT_HOSTNAME
            value: ${CONSOLEDOT_HOSTNAME}
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: CONNEXION_LOG_LEVEL
            value: ${CONNEXION_LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: KAFKA_HOST_INGRESS_GROUP
            value: ${KAFKA_HOST_INGRESS_GROUP}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: KAFKA_SYSTEM_PROFILE_TOPIC
            value: ${KAFKA_SYSTEM_PROFILE_TOPIC}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - name: CLOWDER_ENABLED
            value: "true"
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: INVENTORY_API_CACHE_TIMEOUT_SECONDS
            value: "${INVENTORY_API_CACHE_TIMEOUT_SECONDS}"
          - name: INVENTORY_API_CACHE_TYPE
            value: "${INVENTORY_API_CACHE_TYPE}"
          - name: INVENTORY_CACHE_INSIGHTS_CLIENT_SYSTEM_TIMEOUT_SEC
            value: "${INVENTORY_CACHE_INSIGHTS_CLIENT_SYSTEM_TIMEOUT_SEC}"
          - name: INVENTORY_CACHE_THREAD_POOL_MAX_WORKERS
            value: "${INVENTORY_CACHE_THREAD_POOL_MAX_WORKERS}"
          - name: KAFKA_CONSUMER_SESSION_TIMEOUT_MS
            value: "${KAFKA_CONSUMER_SESSION_TIMEOUT_MS}"
          - name: KAFKA_CONSUMER_HEARTBEAT_INTERVAL_MS
            value: "${KAFKA_CONSUMER_HEARTBEAT_INTERVAL_MS}"
          - name: BYPASS_KESSEL
            value: ${BYPASS_KESSEL}
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - <<: *unleashToken
            name: UNLEASH_TOKEN
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
          - name: UNLEASH_REFRESH_INTERVAL
            value: ${UNLEASH_REFRESH_INTERVAL}
          - name: MQ_DB_BATCH_MAX_SECONDS
            value: ${MQ_DB_BATCH_MAX_SECONDS}
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory-mq-service
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: MQ_DB_BATCH_MAX_MESSAGES
            value: ${MQ_DB_BATCH_MAX_MESSAGES}
          - name: KAFKA_CONSUMER_TOPIC
            value: ${KAFKA_SYSTEM_PROFILE_TOPIC}
          - name: KAFKA_HOST_INGRESS_TOPIC
            value: ${KAFKA_HOST_INGRESS_TOPIC}
          - name: WAIT_FOR_MIGRATIONS_TIMEOUT_SECONDS
            value: ${WAIT_FOR_MIGRATIONS_TIMEOUT_SECONDS}
        resources:
          limits:
            cpu: ${CPU_LIMIT_MQ_SP}
            memory: ${MEMORY_LIMIT_MQ_SP}
          requests:
            cpu: ${CPU_REQUEST_MQ_SP}
            memory: ${MEMORY_REQUEST_MQ_SP}
    - name: mq-workspaces
      replicas: ${{REPLICAS_WORKSPACES}}
      podSpec:
        <<: *mqPodSpec
        initContainers: *migrationWaitInitContainer
        env:
          - name: CONSOLEDOT_HOSTNAME
            value: ${CONSOLEDOT_HOSTNAME}
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: CONNEXION_LOG_LEVEL
            value: ${CONNEXION_LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: KAFKA_HOST_INGRESS_GROUP
            value: ${KAFKA_HOST_INGRESS_GROUP}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: KAFKA_SYSTEM_PROFILE_TOPIC
            value: ${KAFKA_SYSTEM_PROFILE_TOPIC}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - name: CLOWDER_ENABLED
            value: "true"
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: INVENTORY_API_CACHE_TIMEOUT_SECONDS
            value: "${INVENTORY_API_CACHE_TIMEOUT_SECONDS}"
          - name: INVENTORY_API_CACHE_TYPE
            value: "${INVENTORY_API_CACHE_TYPE}"
          - name: INVENTORY_CACHE_INSIGHTS_CLIENT_SYSTEM_TIMEOUT_SEC
            value: "${INVENTORY_CACHE_INSIGHTS_CLIENT_SYSTEM_TIMEOUT_SEC}"
          - name: INVENTORY_CACHE_THREAD_POOL_MAX_WORKERS
            value: "${INVENTORY_CACHE_THREAD_POOL_MAX_WORKERS}"
          - name: KAFKA_CONSUMER_SESSION_TIMEOUT_MS
            value: "${KAFKA_CONSUMER_SESSION_TIMEOUT_MS}"
          - name: KAFKA_CONSUMER_HEARTBEAT_INTERVAL_MS
            value: "${KAFKA_CONSUMER_HEARTBEAT_INTERVAL_MS}"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - <<: *unleashToken
            name: UNLEASH_TOKEN
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
          - name: UNLEASH_REFRESH_INTERVAL
            value: ${UNLEASH_REFRESH_INTERVAL}
          - name: MQ_DB_BATCH_MAX_SECONDS
            value: ${MQ_DB_BATCH_MAX_SECONDS}
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
          - name: KAFKA_CONSUMER_TOPIC
            value: ${KAFKA_KESSEL_WORKSPACES_TOPIC}
          - name: KAFKA_WORKSPACES_TOPIC
            value: ${KAFKA_KESSEL_WORKSPACES_TOPIC}
          - name: MQ_DB_BATCH_MAX_MESSAGES
            value: ${MQ_WORKSPACES_DB_BATCH_MAX_MESSAGES}
          - name: CONSUMER_MQ_BROKER
            value: ${CONSUMER_MQ_BROKER}
          - <<: *rbacPsks
            name: RBAC_PSKS
          - name: WAIT_FOR_MIGRATIONS_TIMEOUT_SECONDS
            value: ${WAIT_FOR_MIGRATIONS_TIMEOUT_SECONDS}
        livenessProbe:
          <<: *mqLivenessProbe
          initialDelaySeconds: 20
          periodSeconds: 20
        readinessProbe:
          <<: *mqReadinessProbe
          failureThreshold: 3
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        resources:
          limits:
            cpu: ${CPU_LIMIT_WORKSPACES_MQ}
            memory: ${MEMORY_LIMIT_WORKSPACES_MQ}
          requests:
            cpu: ${CPU_REQUEST_WORKSPACES_MQ}
            memory: ${MEMORY_REQUEST_WORKSPACES_MQ}
    - name: export-service
      minReplicas: ${{REPLICAS_EXPORT_SVC}}
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        args: ["./inv_export_service.py"]
        env:
        - name: INVENTORY_LOG_LEVEL
          value: DEBUG
        - name: INVENTORY_DB_SSL_MODE
          value: ${INVENTORY_DB_SSL_MODE}
        - name: INVENTORY_DB_SSL_CERT
          value: ${INVENTORY_DB_SSL_CERT}
        - name: KAFKA_EXPORT_SERVICE_TOPIC
          value: ${KAFKA_EXPORT_SERVICE_TOPIC}
        - name: KAFKA_SECURITY_PROTOCOL
          value: ${KAFKA_SECURITY_PROTOCOL}
        - name: KAFKA_SASL_MECHANISM
          value: ${KAFKA_SASL_MECHANISM}
        - name: CLOWDER_ENABLED
          value: "true"
        - name: INVENTORY_DB_SCHEMA
          value: "${INVENTORY_DB_SCHEMA}"
        - name: UNLEASH_URL
          value: ${UNLEASH_URL}
        - <<: *unleashToken
          name: UNLEASH_TOKEN
        - name: EXPORT_SERVICE_TOKEN
          valueFrom:
            secretKeyRef:
              name: export-service-psk
              key: psk
              optional: true
        - name: BYPASS_UNLEASH
          value: ${BYPASS_UNLEASH}
        - name: UNLEASH_REFRESH_INTERVAL
          value: ${UNLEASH_REFRESH_INTERVAL}
        - name: REPLICA_NAMESPACE
          value: ${REPLICA_NAMESPACE}
        livenessProbe: *mqLivenessProbe
        readinessProbe: *mqReadinessProbe
        resources:
          limits:
            cpu: ${CPU_LIMIT_EXPORT_SVC}
            memory: ${MEMORY_LIMIT_EXPORT_SVC}
          requests:
            cpu: ${CPU_REQUEST_EXPORT_SVC}
            memory: ${MEMORY_REQUEST_EXPORT_SVC}
    - name: mq-host-app-data
      replicas: ${{REPLICAS_HOST_APP_DATA}}
      podSpec:
        <<: *mqPodSpec
        initContainers: *migrationWaitInitContainer
        env:
          - name: CONSOLEDOT_HOSTNAME
            value: ${CONSOLEDOT_HOSTNAME}
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: CONNEXION_LOG_LEVEL
            value: ${CONNEXION_LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: KAFKA_HOST_INGRESS_GROUP
            value: ${KAFKA_HOST_APP_DATA_GROUP}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - name: CLOWDER_ENABLED
            value: "true"
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: KAFKA_CONSUMER_SESSION_TIMEOUT_MS
            value: "${KAFKA_CONSUMER_SESSION_TIMEOUT_MS}"
          - name: KAFKA_CONSUMER_HEARTBEAT_INTERVAL_MS
            value: "${KAFKA_CONSUMER_HEARTBEAT_INTERVAL_MS}"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - <<: *unleashToken
            name: UNLEASH_TOKEN
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
          - name: UNLEASH_REFRESH_INTERVAL
            value: ${UNLEASH_REFRESH_INTERVAL}
          - name: MQ_DB_BATCH_MAX_SECONDS
            value: ${MQ_DB_BATCH_MAX_SECONDS}
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
          - name: KAFKA_CONSUMER_TOPIC
            value: ${KAFKA_HOST_APP_DATA_TOPIC}
          - name: KAFKA_HOST_APP_DATA_TOPIC
            value: ${KAFKA_HOST_APP_DATA_TOPIC}
          - name: MQ_DB_BATCH_MAX_MESSAGES
            value: ${MQ_HOST_APP_DATA_DB_BATCH_MAX_MESSAGES}
          - name: WAIT_FOR_MIGRATIONS_TIMEOUT_SECONDS
            value: ${WAIT_FOR_MIGRATIONS_TIMEOUT_SECONDS}
        resources:
          limits:
            cpu: ${CPU_LIMIT_HOST_APP_DATA_MQ}
            memory: ${MEMORY_LIMIT_HOST_APP_DATA_MQ}
          requests:
            cpu: ${CPU_REQUEST_HOST_APP_DATA_MQ}
            memory: ${MEMORY_REQUEST_HOST_APP_DATA_MQ}

    jobs:
    - name: reaper
      schedule: '@hourly'
      concurrencyPolicy: "Forbid"
      suspend: ${{REAPER_SUSPEND}}
      restartPolicy: Never
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        args: ["./jobs/host_reaper.py"]
        env:
          - name: PYTHONPATH
            value: '/opt/app-root/src'
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - <<: *namespaceFieldRef
            name: NAMESPACE
          - name: CLOWDER_ENABLED
            value: "true"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - <<: *unleashToken
            name: UNLEASH_TOKEN
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
          - name: UNLEASH_REFRESH_INTERVAL
            value: ${UNLEASH_REFRESH_INTERVAL}
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
          - name: PAYLOAD_TRACKER_KAFKA_TOPIC
            value: ${PAYLOAD_TRACKER_KAFKA_TOPIC}
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory-mq-service
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: INVENTORY_API_CACHE_TIMEOUT_SECONDS
            value: "${INVENTORY_API_CACHE_TIMEOUT_SECONDS}"
          - name: INVENTORY_API_CACHE_TYPE
            value: "${INVENTORY_API_CACHE_TYPE}"
          - name: INVENTORY_CACHE_INSIGHTS_CLIENT_SYSTEM_TIMEOUT_SEC
            value: "${INVENTORY_CACHE_INSIGHTS_CLIENT_SYSTEM_TIMEOUT_SEC}"
          - name: INVENTORY_CACHE_THREAD_POOL_MAX_WORKERS
            value: "${INVENTORY_CACHE_THREAD_POOL_MAX_WORKERS}"
          - name: HOST_DELETE_CHUNK_SIZE
            value: ${HOST_DELETE_CHUNK_SIZE}
          - <<: *rbacPsks
            name: RBAC_PSKS
        resources:
          limits:
            cpu: ${CPU_LIMIT_REAPER}
            memory: ${MEMORY_LIMIT_REAPER}
          requests:
            cpu: ${CPU_REQUEST_REAPER}
            memory: ${MEMORY_REQUEST_REAPER}
    - name: stale-host-notification
      schedule: ${STALE_HOST_NOTIFICATION_SCHEDULE}
      concurrencyPolicy: "Forbid"
      suspend: ${{STALE_HOST_NOTIFICATION_SUSPEND}}
      restartPolicy: Never
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        args: ["./jobs/generate_stale_host_notifications.py"]
        env:
          - name: PYTHONPATH
            value: '/opt/app-root/src'
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - <<: *namespaceFieldRef
            name: NAMESPACE
          - name: CLOWDER_ENABLED
            value: "true"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - <<: *unleashToken
            name: UNLEASH_TOKEN
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
          - name: UNLEASH_REFRESH_INTERVAL
            value: ${UNLEASH_REFRESH_INTERVAL}
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
          - name: CONNEXION_LOG_LEVEL
            value: ${CONNEXION_LOG_LEVEL}
          - name: CONSOLEDOT_HOSTNAME
            value: ${CONSOLEDOT_HOSTNAME}
        resources:
          limits:
            cpu: ${CPU_LIMIT_STALE_HOST_NOTIFICAION}
            memory: ${MEMORY_LIMIT_STALE_HOST_NOTIFICAION}
          requests:
            cpu: ${CPU_REQUEST_STALE_HOST_NOTIFICAION}
            memory: ${MEMORY_REQUEST_STALE_HOST_NOTIFICAION}
    - name: syndicator
      schedule: ${SYNDICATOR_CRON_SCHEDULE}
      concurrencyPolicy: "Forbid"
      suspend: ${{SYNDICATOR_SUSPEND}}
      restartPolicy: Never
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        args: ["./jobs/inv_publish_hosts.py"]
        env:
          - name: PYTHONPATH
            value: '/opt/app-root/src'
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - <<: *namespaceFieldRef
            name: NAMESPACE
          - name: CLOWDER_ENABLED
            value: "true"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - <<: *unleashToken
            name: UNLEASH_TOKEN
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
          - name: UNLEASH_REFRESH_INTERVAL
            value: ${UNLEASH_REFRESH_INTERVAL}
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
          - name: CREATE_PUBLICATIONS
            value: ${SYNDICATOR_CREATE_PUBLICATIONS}
          - name: DROP_PUBLICATIONS
            value: ${SYNDICATOR_DROP_PUBLICATIONS}
          - name: DROP_REPLICATION_SLOTS
            value: ${SYNDICATOR_DROP_REPLICATION_SLOTS}
          - name: REPLICA_IDENTITY_MODE
            value: ${SYNDICATOR_REPLICA_IDENTITY_MODE}
        resources:
          limits:
            cpu: ${CPU_LIMIT_SYNDICATOR}
            memory: ${MEMORY_LIMIT_SYNDICATOR}
          requests:
            cpu: ${CPU_REQUEST_SYNDICATOR}
            memory: ${MEMORY_REQUEST_SYNDICATOR}
    - name: sp-validator
      schedule: '@hourly'
      suspend: ${{SP_VALIDATOR_SUSPEND}}
      restartPolicy: Never
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        args: ["./jobs/system_profile_validator.py"]
        env:
          - name: PYTHONPATH
            value: '/opt/app-root/src'
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - <<: *namespaceFieldRef
            name: NAMESPACE
          - name: CLOWDER_ENABLED
            value: "true"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - <<: *unleashToken
            name: UNLEASH_TOKEN
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
          - name: UNLEASH_REFRESH_INTERVAL
            value: ${UNLEASH_REFRESH_INTERVAL}
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
          - name: GIT_TOKEN
            valueFrom:
              secretKeyRef:
                key: token
                name: dippy-bot
          - name: GIT_USER
            valueFrom:
              secretKeyRef:
                key: user
                name: dippy-bot
          - name: PAYLOAD_TRACKER_KAFKA_TOPIC
            value: ${PAYLOAD_TRACKER_KAFKA_TOPIC}
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory-mq-service
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: KAFKA_CONSUMER_TOPIC
            value: ${KAFKA_HOST_INGRESS_TOPIC}
          - name: KAFKA_HOST_INGRESS_TOPIC
            value: ${KAFKA_HOST_INGRESS_TOPIC}
          - name: KAFKA_SYSTEM_PROFILE_TOPIC
            value: ${KAFKA_SYSTEM_PROFILE_TOPIC}
          - name: KAFKA_ADDITIONAL_VALIDATION_TOPIC
            value: ${KAFKA_ADDITIONAL_VALIDATION_TOPIC}
          - name: KAFKA_SP_VALIDATOR_MAX_MESSAGES
            value: ${KAFKA_SP_VALIDATOR_MAX_MESSAGES}
        resources:
          limits:
            cpu: ${CPU_LIMIT_SP_VALIDATOR}
            memory: ${MEMORY_LIMIT_SP_VALIDATOR}
          requests:
            cpu: ${CPU_REQUEST_SP_VALIDATOR}
            memory: ${MEMORY_REQUEST_SP_VALIDATOR}
    - name: pendo-syncher
      schedule: ${PENDO_CRON_SCHEDULE}
      suspend: ${{PENDO_SYNCHER_SUSPEND}}
      restartPolicy: Never
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        args: ["./jobs/pendo_syncher.py"]
        env:
          - name: PYTHONPATH
            value: '/opt/app-root/src'
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - <<: *namespaceFieldRef
            name: NAMESPACE
          - name: CLOWDER_ENABLED
            value: "true"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - <<: *unleashToken
            name: UNLEASH_TOKEN
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
          - name: UNLEASH_REFRESH_INTERVAL
            value: ${UNLEASH_REFRESH_INTERVAL}
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
          - name: PENDO_SYNC_ACTIVE
            value: ${PENDO_SYNC_ACTIVE}
          - name: PENDO_INTEGRATION_KEY
            valueFrom:
              secretKeyRef:
                key: apikey
                name: pendo-creds
        resources:
          limits:
            cpu: ${CPU_LIMIT_PENDO_SYNCHER}
            memory: ${MEMORY_LIMIT_PENDO_SYNCHER}
          requests:
            cpu: ${CPU_REQUEST_PENDO_SYNCHER}
            memory: ${MEMORY_REQUEST_PENDO_SYNCHER}
    - name: synchronizer
      restartPolicy: OnFailure
      podSpec: &synchronizerPodSpec
        image: ${IMAGE}:${IMAGE_TAG}
        args: ["./jobs/rebuild_events_topic.py", "&&", "./jobs/host_synchronizer.py"]
        env:
          - name: PYTHONPATH
            value: '/opt/app-root/src'
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - <<: *namespaceFieldRef
            name: NAMESPACE
          - name: CLOWDER_ENABLED
            value: "true"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - <<: *unleashToken
            name: UNLEASH_TOKEN
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
          - name: UNLEASH_REFRESH_INTERVAL
            value: ${UNLEASH_REFRESH_INTERVAL}
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
          - name: PAYLOAD_TRACKER_KAFKA_TOPIC
            value: ${PAYLOAD_TRACKER_KAFKA_TOPIC}
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory-mq-service
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: SCRIPT_CHUNK_SIZE
            value: ${SCRIPT_CHUNK_SIZE}
          - name: REBUILD_EVENTS_TIME_LIMIT
            value: ${REBUILD_EVENTS_TIME_LIMIT}
        resources: &synchronizerResources
          limits:
            cpu: ${CPU_LIMIT_SYNCHRONIZER}
            memory: ${MEMORY_LIMIT_SYNCHRONIZER}
          requests:
            cpu: ${CPU_REQUEST_SYNCHRONIZER}
            memory: ${MEMORY_REQUEST_SYNCHRONIZER}
    - name: synchronizer-only
      restartPolicy: OnFailure
      podSpec:
        <<: *synchronizerPodSpec
        args: ["./jobs/host_synchronizer.py"]
    - name: sync-host-groups
      restartPolicy: OnFailure
      podSpec:
        <<: *synchronizerPodSpec
        args: ["./jobs/host_sync_group_data.py"]
    - name: delete-hosts-s3
      restartPolicy: OnFailure
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        args: ["./jobs/delete_hosts_s3.py"]
        env:
          - name: PYTHONPATH
            value: '/opt/app-root/src'
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - <<: *namespaceFieldRef
            name: NAMESPACE
          - name: CLOWDER_ENABLED
            value: "true"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - <<: *unleashToken
            name: UNLEASH_TOKEN
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
          - name: UNLEASH_REFRESH_INTERVAL
            value: ${UNLEASH_REFRESH_INTERVAL}
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
          - name: DRY_RUN
            value: ${DELETE_HOSTS_DRY_RUN}
          - name: DELETE_HOSTS_S3_BATCH_SIZE
            value: ${DELETE_HOSTS_S3_BATCH_SIZE}
          - name: S3_AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: ${DELETE_HOSTS_S3_AWS_SECRET}
                key: aws_access_key_id
          - name: S3_AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: ${DELETE_HOSTS_S3_AWS_SECRET}
                key: aws_secret_access_key
          - name: S3_AWS_BUCKET
            valueFrom:
              secretKeyRef:
                name: ${DELETE_HOSTS_S3_AWS_SECRET}
                key: bucket
          - name: SUSPEND_JOB
            value: ${SUSPEND_DELETE_HOSTS_S3}
        resources:
          limits:
            cpu: ${CPU_LIMIT_DELETE_HOSTS_S3}
            memory: ${MEMORY_LIMIT_DELETE_HOSTS_S3}
          requests:
            cpu: ${CPU_REQUEST_DELETE_HOSTS_S3}
            memory: ${MEMORY_REQUEST_DELETE_HOSTS_S3}
    - name: duplicate-hosts-remover
      restartPolicy: Never
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        args: [ "./jobs/host_delete_duplicates.py" ]
        env:
          - name: PYTHONPATH
            value: '/opt/app-root/src'
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - <<: *namespaceFieldRef
            name: NAMESPACE
          - name: CLOWDER_ENABLED
            value: "true"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - <<: *unleashToken
            name: UNLEASH_TOKEN
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
          - name: UNLEASH_REFRESH_INTERVAL
            value: ${UNLEASH_REFRESH_INTERVAL}
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
          - name: PAYLOAD_TRACKER_KAFKA_TOPIC
            value: ${PAYLOAD_TRACKER_KAFKA_TOPIC}
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory-mq-service
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: SCRIPT_CHUNK_SIZE
            value: ${SCRIPT_CHUNK_SIZE}
          - name: DRY_RUN
            value: ${REMOVE_DUPLICATES_DRY_RUN}
          - name: SUSPEND_JOB
            value: ${SUSPEND_DUPLICATE_HOSTS_REMOVER}
        resources:
          limits:
            cpu: ${CPU_LIMIT_DUPLICATE_HOSTS_REMOVER_JOB}
            memory: ${MEMORY_LIMIT_DUPLICATE_HOSTS_REMOVER_JOB}
          requests:
            cpu: ${CPU_REQUEST_DUPLICATE_HOSTS_REMOVER_JOB}
            memory: ${MEMORY_REQUEST_DUPLICATE_HOSTS_REMOVER_JOB}
    - name: create-ungrouped-host-groups
      restartPolicy: OnFailure
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        args: ["./jobs/create_ungrouped_host_groups.py"]
        env:
          - name: PYTHONPATH
            value: '/opt/app-root/src'
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - <<: *namespaceFieldRef
            name: NAMESPACE
          - name: CLOWDER_ENABLED
            value: "true"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - <<: *unleashToken
            name: UNLEASH_TOKEN
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
          - name: UNLEASH_REFRESH_INTERVAL
            value: ${UNLEASH_REFRESH_INTERVAL}
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
          - name: CREATE_UNGROUPED_GROUPS_BATCH_SIZE
            value: ${CREATE_UNGROUPED_GROUPS_BATCH_SIZE}
        resources: &ungroupedHostResources
          limits:
            cpu: ${CPU_LIMIT_UNGROUPED_HOSTS_JOB}
            memory: ${MEMORY_LIMIT_UNGROUPED_HOSTS_JOB}
          requests:
            cpu: ${CPU_REQUEST_UNGROUPED_HOSTS_JOB}
            memory: ${MEMORY_REQUEST_UNGROUPED_HOSTS_JOB}
    - name: assign-ungrouped-host-groups
      restartPolicy: OnFailure
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        args: ["./jobs/assign_ungrouped_hosts_to_groups.py"]
        env:
          - name: PYTHONPATH
            value: '/opt/app-root/src'
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - <<: *namespaceFieldRef
            name: NAMESPACE
          - name: CLOWDER_ENABLED
            value: "true"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - <<: *unleashToken
            name: UNLEASH_TOKEN
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
          - name: UNLEASH_REFRESH_INTERVAL
            value: ${UNLEASH_REFRESH_INTERVAL}
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
          - name: PAYLOAD_TRACKER_KAFKA_TOPIC
            value: ${PAYLOAD_TRACKER_KAFKA_TOPIC}
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory-mq-service
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: ASSIGN_UNGROUPED_GROUPS_BATCH_SIZE
            value: ${ASSIGN_UNGROUPED_GROUPS_BATCH_SIZE}
        resources: *ungroupedHostResources
    - name: update-rhsm-host-timestamps
      restartPolicy: Never
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        args: [ "./jobs/update_rhsm_host_timestamps.py" ]
        env:
          - name: PYTHONPATH
            value: '/opt/app-root/src'
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: PAYLOAD_TRACKER_KAFKA_TOPIC
            value: ${PAYLOAD_TRACKER_KAFKA_TOPIC}
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory-mq-service
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - <<: *namespaceFieldRef
            name: NAMESPACE
          - name: CLOWDER_ENABLED
            value: "true"
          - name: SCRIPT_CHUNK_SIZE
            value: ${SCRIPT_CHUNK_SIZE}
          - name: DRY_RUN
            value: ${UPDATE_RHSM_HOST_TIMESTAMPS_DRY_RUN}
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
        resources:
          limits:
            cpu: ${CPU_LIMIT_UPDATE_RHSM_HOST_TIMESTAMPS_JOB}
            memory: ${MEMORY_LIMIT_UPDATE_RHSM_HOST_TIMESTAMPS_JOB}
          requests:
            cpu: ${CPU_REQUEST_UPDATE_RHSM_HOST_TIMESTAMPS_JOB}
            memory: ${MEMORY_REQUEST_UPDATE_RHSM_HOST_TIMESTAMPS_JOB}
    - name: backfill-per-reporter-culled-timestamps
      restartPolicy: Never
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        args: [ "./jobs/backfill_per_reporter_culled_timestamps.py" ]
        env:
          - name: PYTHONPATH
            value: '/opt/app-root/src'
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: PAYLOAD_TRACKER_KAFKA_TOPIC
            value: ${PAYLOAD_TRACKER_KAFKA_TOPIC}
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory-mq-service
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - <<: *namespaceFieldRef
            name: NAMESPACE
          - name: CLOWDER_ENABLED
            value: "true"
          - name: SCRIPT_CHUNK_SIZE
            value: ${SCRIPT_CHUNK_SIZE}
          - name: DRY_RUN
            value: ${BACKFILL_PER_REPORTER_CULLED_TIMESTAMPS_DRY_RUN}
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
        resources:
          limits:
            cpu: ${CPU_LIMIT_BACKFILL_PER_REPORTER_CULLED_TIMESTAMPS_JOB}
            memory: ${MEMORY_LIMIT_BACKFILL_PER_REPORTER_CULLED_TIMESTAMPS_JOB}
          requests:
            cpu: ${CPU_REQUEST_BACKFILL_PER_REPORTER_CULLED_TIMESTAMPS_JOB}
            memory: ${MEMORY_REQUEST_BACKFILL_PER_REPORTER_CULLED_TIMESTAMPS_JOB}
    - name: populate-host-type
      restartPolicy: Never
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        args: [ "./jobs/populate_host_type.py" ]
        env:
          - name: PYTHONPATH
            value: '/opt/app-root/src'
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: PAYLOAD_TRACKER_KAFKA_TOPIC
            value: ${PAYLOAD_TRACKER_KAFKA_TOPIC}
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory-mq-service
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - <<: *namespaceFieldRef
            name: NAMESPACE
          - name: CLOWDER_ENABLED
            value: "true"
          - name: SCRIPT_CHUNK_SIZE
            value: ${SCRIPT_CHUNK_SIZE}
          - name: DRY_RUN
            value: ${POPULATE_HOST_TYPE_DRY_RUN}
          - name: SUSPEND_JOB
            value: ${POPULATE_HOST_TYPE_SUSPEND_JOB}
          - name: POPULATE_HOST_TYPE_BATCH_SIZE
            value: ${POPULATE_HOST_TYPE_BATCH_SIZE}
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
        resources:
          limits:
            cpu: ${CPU_LIMIT_POPULATE_HOST_TYPE_JOB}
            memory: ${MEMORY_LIMIT_POPULATE_HOST_TYPE_JOB}
          requests:
            cpu: ${CPU_REQUEST_POPULATE_HOST_TYPE_JOB}
            memory: ${MEMORY_REQUEST_POPULATE_HOST_TYPE_JOB}
    - name: run-db-migrations
      restartPolicy: OnFailure
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        args: ["FLASK_APP=./manage.py", "flask", "db", "upgrade"]
        env:
          - name: PYTHONPATH
            value: '/opt/app-root/src'
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: INVENTORY_DB_SCHEMA
            value: "${INVENTORY_DB_SCHEMA}"
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - <<: *namespaceFieldRef
            name: NAMESPACE
          - name: CLOWDER_ENABLED
            value: "true"
          - name: REPLICA_NAMESPACE
            value: ${REPLICA_NAMESPACE}
        resources:
          limits:
            cpu: ${CPU_LIMIT_DB_MIGRATIONS_JOB}
            memory: ${MEMORY_LIMIT_DB_MIGRATIONS_JOB}
          requests:
            cpu: ${CPU_REQUEST_DB_MIGRATIONS_JOB}
            memory: ${MEMORY_REQUEST_DB_MIGRATIONS_JOB}
    database:
      name: ${DB_NAME}
      version: 16
    kafkaTopics: # The number of Kafka partitions variables provided are the Ephemeral environments.
      - topicName: ${KAFKA_SYSTEM_PROFILE_TOPIC}
        partitions: ${{NUMBER_OF_KAFKA_SYSTEM_PROFILE_TOPIC_PARTITIONS}}
      - topicName: ${PAYLOAD_TRACKER_KAFKA_TOPIC}
        partitions: ${{NUMBER_OF_PAYLOAD_TRACKER_KAFKA_TOPIC_PARTITIONS}}
      - topicName: ${KAFKA_EVENT_TOPIC}
        partitions: ${{NUMBER_OF_KAFKA_EVENT_TOPIC_PARTITIONS}}
      - topicName: ${KAFKA_NOTIFICATION_TOPIC}
        partitions: ${{NUMBER_OF_KAFKA_NOTIFICATION_TOPIC_PARTITIONS}}
      - topicName: ${KAFKA_HOST_INGRESS_TOPIC}
        partitions: ${{NUMBER_OF_KAFKA_HOST_INGRESS_TOPIC_PARTITIONS}}
      - topicName: ${KAFKA_HOST_INGRESS_P1_TOPIC}
        partitions: ${{NUMBER_OF_KAFKA_HOST_INGRESS_P1_TOPIC_PARTITIONS}}
      - topicName: ${KAFKA_EXPORT_SERVICE_TOPIC}
        partitions: ${{NUMBER_OF_KAFKA_EXPORT_SERVICE_TOPIC_PARTITIONS}}
      - topicName: ${KAFKA_KESSEL_WORKSPACES_TOPIC}
        partitions: ${{NUMBER_OF_KAFKA_KESSEL_WORKSPACES_TOPIC_PARTITIONS}}
      - topicName: ${KAFKA_HOST_APP_DATA_TOPIC}
        partitions: ${{NUMBER_OF_KAFKA_HOST_APP_DATA_TOPIC_PARTITIONS}}
# this service proxies requests for the old URL (insights-inventory:8080) to the clowderized service (host-inventory-service:8000)
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app: insights-inventory
    name: insights-inventory
  spec:
    ports:
    - name: port-8080
      port: 8080
      protocol: TCP
      targetPort: 8000
    selector:
      pod: host-inventory-service
- apiVersion: metrics.console.redhat.com/v1alpha1
  kind: FloorPlan
  metadata:
    name: host-inventory
  spec:
    database:
      secretName: ${FLOORIST_DB_SECRET_NAME}
    objectStore:
      secretName: ${FLOORIST_BUCKET_SECRET_NAME}
    suspend: ${{FLOORIST_SUSPEND}}
    logLevel: ${FLOORIST_LOGLEVEL}
    queries:
      - prefix: insights/inventory/hosts
        chunksize: 50000
        query: >-
          SELECT
            "id",
            "account" AS "account_number",
            "created_on" AS "created_at",
            "modified_on" AS "updated_at",
            "ansible_host" AS "ansible_host",
            CONCAT_WS('.',"sps"."operating_system"->>'name',"sps"."operating_system"->'major',"sps"."operating_system"->'minor') AS "os_version",
            "sps"."host_type" AS "host_type",
            "spd"."workloads"->'ansible'->'controller_version' AS "ansible_controller_version",
            "spd"."workloads"->'ansible'->'hub_version' AS "ansible_hub_version",
            "sps"."rhsm"->'version' AS "rhsm_version",
            "sps"."is_marketplace" AS "is_marketplace_installation",
            "sps"."insights_client_version" AS "insights_client_version",
            "spd"."insights_egg_version" AS "insights_egg_version",
            "sps"."satellite_managed" AS "is_satellite_managed",
            "sps"."subscription_status" AS "subscription_status",
            "spd"."workloads"->'ansible' AS "ansible_workload",
            "spd"."workloads"->'mssql' AS "mssql_workload",
            "spd"."workloads"->'sap' AS "sap_workload",
            "sps"."rhc_client_id"::text AS "rhc_client_id"
          FROM "hbi"."hosts" AS "h"
          LEFT JOIN "hbi"."system_profiles_static" AS "sps"
            ON "h"."org_id" = "sps"."org_id" AND "h"."id" = "sps"."host_id"
          LEFT JOIN "hbi"."system_profiles_dynamic" AS "spd"
            ON "h"."org_id" = "spd"."org_id" AND "h"."id" = "spd"."host_id"
- apiVersion: metrics.console.redhat.com/v1alpha1
  kind: FloorPlan
  metadata:
    name: host-inventory-hms
  spec:
    database:
      secretName: ${FLOORIST_DB_SECRET_NAME}
    objectStore:
      secretName: ${FLOORIST_HMS_BUCKET_SECRET_NAME}
    suspend: ${{FLOORIST_SUSPEND}}
    logLevel: ${FLOORIST_LOGLEVEL}
    queries:
#      - prefix: hms_analytics/inventory/${ENV_NAME}/hosts
#        query: >-
#          SELECT
#            "id",
#            COALESCE("account", '0') AS "account",
#            "org_id" AS "org_id",
#            "created_on" AS "created_at",
#            "modified_on" AS "updated_at",
#            "reporter" AS "reporter",
#            "insights_id" AS "insights_id",
#            "subscription_manager_id" AS "subscription_manager_id",
#            "bios_uuid" AS "bios_uuid",
#            "provider_id" AS "provider_id",
#            "provider_type" AS "provider_type"
#          FROM "hbi"."hosts";
      - prefix: hms_analytics/inventory/${ENV_NAME}/groups
        chunksize: 10000
        query: >-
          SELECT
            "id",
            "org_id" AS "org_id",
            COALESCE("account", '0') AS "account",
            "name" AS "name",
            "created_on" AS "created_at",
            "modified_on" AS "updated_at"
          FROM "hbi"."groups"
          WHERE "ungrouped" IS FALSE;
      - prefix: hms_analytics/inventory/${ENV_NAME}/hosts_metrics/hosts_count
        query: >-
          SELECT COUNT(*) AS "hosts_count"
          FROM "hbi"."hosts";
      - prefix: hms_analytics/inventory/${ENV_NAME}/groups_metrics/groups_count
        query: >-
          SELECT COUNT(*) AS "group_counts"
          FROM "hbi"."groups"
          WHERE "ungrouped" IS FALSE;
      - prefix: hms_analytics/inventory/${ENV_NAME}/hosts_metrics/daily_created_by_reporters
        query: >-
          SELECT
            "reporter" AS "reporter",
            count(*) AS "hosts_created"
          FROM "hbi"."hosts"
          WHERE "created_on" >= NOW() - INTERVAL '1 day'
          GROUP BY "reporter";
      - prefix: hms_analytics/inventory/${ENV_NAME}/hosts_metrics/daily_updated_by_reporters
        query: >-
          SELECT  "reporter" AS "reporter", count(*) AS "hosts_updated"
          FROM "hbi"."hosts"
          WHERE "modified_on" >= NOW() - INTERVAL '1 day'
          GROUP BY "reporter";
      - prefix: hms_analytics/inventory/${ENV_NAME}/hosts_metrics/hosts_per_org_id
        chunksize: 10000
        query: >-
          SELECT
            "org_id" AS "org_id",
            COUNT(*) AS "host_count"
          FROM "hbi"."hosts"
          GROUP BY "org_id"
          ORDER BY "host_count" DESC;
      - prefix: hms_analytics/inventory/${ENV_NAME}/hosts_metrics/hosts_per_public_cloud
        query: >-
          SELECT
            "provider_type" AS "provider_type",
            COUNT(*) AS "host_count"
          FROM "hbi"."hosts"
          GROUP BY "provider_type";
      - prefix: hms_analytics/inventory/${ENV_NAME}/hosts_metrics/org_id_by_system_update_method
        chunksize: 10000
        query: >-
          SELECT
            "org_id",
            COUNT(*) FILTER (WHERE
              "system_profile_facts"->'bootc_status'->'booted'->>'image_digest' IS NOT NULL
              AND "system_profile_facts"->'bootc_status'->'booted'->>'image_digest' <> ''
            ) AS "image_mode_count",
            COUNT(*) FILTER (WHERE
              "system_profile_facts"->'bootc_status'->'booted'->>'image_digest' IS NULL
              AND "system_profile_facts"->>'host_type' IS NULL
            ) AS "package_mode_count",
            COUNT(*) FILTER (WHERE
              "system_profile_facts"->>'host_type' = 'edge'
            ) AS "edge_count"
          FROM "hbi"."hosts"
          GROUP BY "org_id";
      - prefix: hms_analytics/inventory/${ENV_NAME}/hosts_metrics/duplicated_hosts_by_org
        chunksize: 10000
        query: >-
          SELECT
            "aa"."org_id",
            "aa"."id_value",
            "aa"."hosts_count",
            "aa"."reporter",
            "aa"."id_type"
          FROM (
            SELECT
              "org_id",
              "insights_id"::text AS "id_value",
              COUNT(*) AS "hosts_count",
              "reporter",
              'insights_id' AS "id_type"
            FROM
              "hbi"."hosts"
            WHERE
              "provider_id" IS NULL
              AND "insights_id" != '00000000-0000-0000-0000-000000000000'::uuid
            GROUP BY
              "org_id",
              "insights_id",
              "reporter"

            UNION ALL

            SELECT
              "org_id",
              "subscription_manager_id" AS "id_value",
              COUNT(*) AS "hosts_count",
              "reporter",
              'subscription_manager_id' AS "id_type"
            FROM
              "hbi"."hosts"
            WHERE
              "provider_id" IS NULL
              AND "insights_id" = '00000000-0000-0000-0000-000000000000'::uuid
              AND "subscription_manager_id" IS NOT NULL
            GROUP BY
              "org_id",
              "subscription_manager_id",
              "reporter"
          ) AS "aa"
          WHERE
            "aa"."hosts_count" > 1
          ORDER BY
            "aa"."org_id" ASC,
            "aa"."id_type" ASC;
      - prefix: hms_analytics/inventory/${ENV_NAME}/groups_metrics/org_ids_with_group_names
        chunksize: 10000
        query: >-
          SELECT
            DISTINCT "org_id" AS "org_id", "name" AS "name"
          FROM "hbi"."groups"
          ORDER BY "name" ASC;
      - prefix: hms_analytics/inventory/${ENV_NAME}/groups_metrics/hosts_per_groups
        chunksize: 10000
        query: >-
          SELECT
            "id" AS "group_id",
            "name" AS "group_name",
            COUNT(*) AS "host_count"
          FROM "hbi"."groups"
          JOIN "hbi"."hosts_groups" ON "groups"."id" = "hbi"."hosts_groups"."group_id"
          WHERE "ungrouped" IS FALSE
          GROUP BY "groups"."id"
          ORDER BY "host_count" DESC;
- apiVersion: v1
  data:
    nginx.conf: |-
      worker_processes  1;
      error_log  /dev/stderr warn;
      pid        /run/nginx.pid;

      events {
        worker_connections  1024;
      }
      http {
        log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_proto" "$http_x_forwarded_for"';

        access_log  /dev/stdout  main;

        sendfile            on;
        tcp_nopush          on;
        tcp_nodelay         on;
        keepalive_timeout   65;
        server_tokens       off;

        upstream host-inventory-service-reads {
          server host-inventory-service-reads:8000;
          server host-inventory-service-secondary-reads:8000;
        }
        upstream host-inventory-service-writes {
          server host-inventory-service-writes:8000;
        }
        map $request_method $upstream_location {
                    GET     host-inventory-service-reads;
                    HEAD    host-inventory-service-reads;
                    POST    host-inventory-service-writes;
                    PUT     host-inventory-service-writes;
                    DELETE  host-inventory-service-writes;
                    default host-inventory-service-writes;
        }
        server {
          error_log  stderr;
          listen 8000;
          listen 9000;

          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
          proxy_set_header X-Forwarded-Proto $http_x_forwarded_proto;
          proxy_set_header Host $http_host;
          proxy_redirect off;

          client_max_body_size 500M;
          client_header_buffer_size 46k;
          location /healthz {
              auth_basic          off;
              allow               all;
              return              200;
          }
          location /metrics {
              auth_basic          off;
              allow               all;
              return              200;
          }
          location / {
            proxy_pass http://$upstream_location;
            proxy_read_timeout 600s;
          }
        }
      }
  kind: ConfigMap
  metadata:
    name: inventory-nginx-conf

- apiVersion: v1
  kind: Secret
  metadata:
    name: rbac-psks
  data:
    psks.json: >-
      ewogICJhZHZpc29yIjogewogICAgImFsdC1zZWNyZXQiOiAiMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTEiCiAgfSwKICAiYXBwcm92YWwiOiB7CiAgICAiYWx0LXNlY3JldCI6ICIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMiIKICB9LAogICJub3RpZmljYXRpb25zIjogewogICAgImFsdC1zZWNyZXQiOiAiMzMzMzMzMzMzMzMzMzMzMzMzMzMzMzMzMzMzMzMzMzMiCiAgfSwKICAiaW52ZW50b3J5IjogewogICAgInNlY3JldCI6ICI0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQiCiAgfQp9
  type: Opaque

parameters:
# =================================================================================
# I. Core Application Configuration
# =================================================================================
# High-level settings defining the application's identity, image, and environment.

- description: ClowdApp name
  name: CLOWDAPP_NAME
  value: host-inventory
- description: ClowdEnvironment name
  name: ENV_NAME
  value: stage
- description: Image NAME
  name: IMAGE
  required: true
  value: quay.io/redhat-services-prod/insights-management-tenant/insights-host-inventory/insights-host-inventory
- description: Image tag
  name: IMAGE_TAG
  required: true
- name: APP_NAME
  value: inventory
- name: LOG_LEVEL
  value: INFO

# =================================================================================
# II. Deployment Replicas & Resources
# =================================================================================
# Controls scaling and resource allocation for each component.

# -- Replica Counts --
- description: Replica count for webservice reads
  name: REPLICAS_SVC_READS
  value: "7"
- description: Replica count for secondary webservice reads
  name: REPLICAS_SVC_SECONDARY_READS
  value: "1"
- description: Replica count for webservice writes
  name: REPLICAS_SVC_WRITES
  value: "3"
- description: Replica count for pmin Kafka consumer
  name: REPLICAS_PMIN
  value: "3"
- description: Replica count for p1 Kafka consumer
  name: REPLICAS_P1
  value: "5"
- description: Replica count for sp Kafka consumer
  name: REPLICAS_SP
  value: "2"
- description: Replica count for mq-workspaces consumer
  name: REPLICAS_WORKSPACES
  value: "1"
- description: Replica count for export-service
  name: REPLICAS_EXPORT_SVC
  value: "2"
- description: Replica count for mq-host-app-data consumer
  name: REPLICAS_HOST_APP_DATA
  value: "1"

# -- NGINX Resources --
- displayName: Minimum replicas for NGINX
  name: NGINX_REPLICAS
  required: true
  value: "1"
- name: NGINX_CPU_REQUEST
  value: 100m
- name: NGINX_CPU_LIMIT
  value: 200m
- name: NGINX_MEMORY_REQUEST
  value: 100Mi
- name: NGINX_MEMORY_LIMIT
  value: 200Mi

# -- API Service Resources (service-reads/writes) --
- name: CPU_REQUEST_SERVICE
  value: 250m
- name: CPU_LIMIT_SERVICE
  value: 500m
- name: MEMORY_REQUEST_SERVICE
  value: 256Mi
- name: MEMORY_LIMIT_SERVICE
  value: 512Mi

# -- MQ Consumer Resources --
- name: CPU_REQUEST_MQ_PMIN
  value: 250m
- name: CPU_LIMIT_MQ_PMIN
  value: 500m
- name: MEMORY_REQUEST_MQ_PMIN
  value: 256Mi
- name: MEMORY_LIMIT_MQ_PMIN
  value: 512Mi
- name: CPU_REQUEST_MQ_P1
  value: 250m
- name: CPU_LIMIT_MQ_P1
  value: 500m
- name: MEMORY_REQUEST_MQ_P1
  value: 256Mi
- name: MEMORY_LIMIT_MQ_P1
  value: 512Mi
- name: CPU_REQUEST_MQ_SP
  value: 250m
- name: CPU_LIMIT_MQ_SP
  value: 500m
- name: MEMORY_REQUEST_MQ_SP
  value: 256Mi
- name: MEMORY_LIMIT_MQ_SP
  value: 512Mi
- name: CPU_REQUEST_WORKSPACES_MQ
  value: 250m
- name: CPU_LIMIT_WORKSPACES_MQ
  value: 500m
- name: MEMORY_REQUEST_WORKSPACES_MQ
  value: 512Mi
- name: MEMORY_LIMIT_WORKSPACES_MQ
  value: 1Gi
- name: CPU_REQUEST_EXPORT_SVC
  value: 250m
- name: CPU_LIMIT_EXPORT_SVC
  value: 500m
- name: MEMORY_REQUEST_EXPORT_SVC
  value: 256Mi
- name: MEMORY_LIMIT_EXPORT_SVC
  value: 512Mi
- name: CPU_REQUEST_HOST_APP_DATA_MQ
  value: 250m
- name: CPU_LIMIT_HOST_APP_DATA_MQ
  value: 500m
- name: MEMORY_REQUEST_HOST_APP_DATA_MQ
  value: 256Mi
- name: MEMORY_LIMIT_HOST_APP_DATA_MQ
  value: 512Mi

# -- Job Resources --
- name: CPU_REQUEST_REAPER
  value: 250m
- name: CPU_LIMIT_REAPER
  value: 500m
- name: MEMORY_REQUEST_REAPER
  value: 256Mi
- name: MEMORY_LIMIT_REAPER
  value: 512Mi
- name: CPU_REQUEST_STALE_HOST_NOTIFICAION
  value: 250m
- name: CPU_LIMIT_STALE_HOST_NOTIFICAION
  value: 500m
- name: MEMORY_REQUEST_STALE_HOST_NOTIFICAION
  value: 256Mi
- name: MEMORY_LIMIT_STALE_HOST_NOTIFICAION
  value: 512Mi
- name: CPU_REQUEST_SP_VALIDATOR
  value: 250m
- name: CPU_LIMIT_SP_VALIDATOR
  value: 500m
- name: MEMORY_REQUEST_SP_VALIDATOR
  value: 256Mi
- name: MEMORY_LIMIT_SP_VALIDATOR
  value: 512Mi
- name: CPU_REQUEST_PENDO_SYNCHER
  value: 250m
- name: CPU_LIMIT_PENDO_SYNCHER
  value: 500m
- name: MEMORY_REQUEST_PENDO_SYNCHER
  value: 256Mi
- name: MEMORY_LIMIT_PENDO_SYNCHER
  value: 512Mi
- name: CPU_REQUEST_SYNCHRONIZER
  value: 250m
- name: CPU_LIMIT_SYNCHRONIZER
  value: 500m
- name: MEMORY_REQUEST_SYNCHRONIZER
  value: 256Mi
- name: MEMORY_LIMIT_SYNCHRONIZER
  value: 512Mi
- name: CPU_REQUEST_DELETE_HOSTS_S3
  value: 250m
- name: CPU_LIMIT_DELETE_HOSTS_S3
  value: 500m
- name: MEMORY_REQUEST_DELETE_HOSTS_S3
  value: 0.5Gi
- name: MEMORY_LIMIT_DELETE_HOSTS_S3
  value: 1Gi
- name: CPU_REQUEST_SYNDICATOR
  value: 250m
- name: CPU_LIMIT_SYNDICATOR
  value: 500m
- name: MEMORY_REQUEST_SYNDICATOR
  value: 256Mi
- name: MEMORY_LIMIT_SYNDICATOR
  value: 512Mi
- name: CPU_REQUEST_UNGROUPED_HOSTS_JOB
  value: 250m
- name: CPU_LIMIT_UNGROUPED_HOSTS_JOB
  value: 500m
- name: MEMORY_REQUEST_UNGROUPED_HOSTS_JOB
  value: 256Mi
- name: MEMORY_LIMIT_UNGROUPED_HOSTS_JOB
  value: 512Mi
- name: CPU_REQUEST_DUPLICATE_HOSTS_REMOVER_JOB
  value: 250m
- name: CPU_LIMIT_DUPLICATE_HOSTS_REMOVER_JOB
  value: 500m
- name: MEMORY_REQUEST_DUPLICATE_HOSTS_REMOVER_JOB
  value: 256Mi
- name: MEMORY_LIMIT_DUPLICATE_HOSTS_REMOVER_JOB
  value: 512Mi
- name: CPU_REQUEST_UPDATE_RHSM_HOST_TIMESTAMPS_JOB
  value: 250m
- name: CPU_LIMIT_UPDATE_RHSM_HOST_TIMESTAMPS_JOB
  value: 500m
- name: MEMORY_REQUEST_UPDATE_RHSM_HOST_TIMESTAMPS_JOB
  value: 256Mi
- name: MEMORY_LIMIT_UPDATE_RHSM_HOST_TIMESTAMPS_JOB
  value: 512Mi
- name: CPU_REQUEST_BACKFILL_PER_REPORTER_CULLED_TIMESTAMPS_JOB
  value: 250m
- name: CPU_LIMIT_BACKFILL_PER_REPORTER_CULLED_TIMESTAMPS_JOB
  value: 500m
- name: MEMORY_REQUEST_BACKFILL_PER_REPORTER_CULLED_TIMESTAMPS_JOB
  value: 256Mi
- name: MEMORY_LIMIT_BACKFILL_PER_REPORTER_CULLED_TIMESTAMPS_JOB
  value: 512Mi
- name: CPU_REQUEST_POPULATE_HOST_TYPE_JOB
  value: 250m
- name: CPU_LIMIT_POPULATE_HOST_TYPE_JOB
  value: 500m
- name: MEMORY_REQUEST_POPULATE_HOST_TYPE_JOB
  value: 256Mi
- name: MEMORY_LIMIT_POPULATE_HOST_TYPE_JOB
  value: 512Mi
- name: CPU_REQUEST_DB_MIGRATIONS_JOB
  value: 250m
- name: CPU_LIMIT_DB_MIGRATIONS_JOB
  value: 500m
- name: MEMORY_REQUEST_DB_MIGRATIONS_JOB
  value: 256Mi
- name: MEMORY_LIMIT_DB_MIGRATIONS_JOB
  value: 512Mi

# =================================================================================
# III. External Services & Dependencies
# =================================================================================

# -- Kafka Configuration --
- name: KAFKA_BOOTSTRAP_HOST
  value: 'localhost'
- name: KAFKA_BOOTSTRAP_PORT
  value: '29092'
- name: KAFKA_SECURITY_PROTOCOL
  description: The Kafka Security Protocol
  value: PLAINTEXT
- name: KAFKA_SASL_MECHANISM
  value: 'PLAIN'
- name: KAFKA_PRODUCER_ACKS
  value: '1'
- name: KAFKA_PRODUCER_RETRIES
  value: '0'
- name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
  value: '100'
- name: KAFKA_CONSUMER_SESSION_TIMEOUT_MS
  value: '10000'
- name: KAFKA_CONSUMER_HEARTBEAT_INTERVAL_MS
  value: '3000'
- name: KAFKA_HOST_INGRESS_GROUP
  description: The Kafka consumer group name
  value: inventory-mq
- name: KAFKA_HOST_INGRESS_TOPIC
  description: The topic containing Host data sent by reporters
  value: platform.inventory.host-ingress
- name: NUMBER_OF_KAFKA_HOST_INGRESS_TOPIC_PARTITIONS
  description: Number of partitions for the Kafka host ingress topic
  value: '1'
- name: KAFKA_HOST_INGRESS_P1_TOPIC
  description: The TOP-PRIORITY topic containing Host data sent by reporters
  value: platform.inventory.host-ingress-p1
- name: NUMBER_OF_KAFKA_HOST_INGRESS_P1_TOPIC_PARTITIONS
  description: Number of partitions for the Kafka host ingress P1 topic
  value: '1'
- name: KAFKA_EVENT_TOPIC
  description: The topic for Host data that were processed by Inventory
  value: platform.inventory.events
- name: NUMBER_OF_KAFKA_EVENT_TOPIC_PARTITIONS
  description: Number of partitions for the Kafka event topic
  value: '1'
- name: KAFKA_NOTIFICATION_TOPIC
  description: The topic containing messages to be sent as notifications
  value: platform.notifications.ingress
- name: NUMBER_OF_KAFKA_NOTIFICATION_TOPIC_PARTITIONS
  description: Number of partitions for the Kafka notification topic
  value: '1'
- name: KAFKA_SYSTEM_PROFILE_TOPIC
  description: The topic containing Host data for System Profile updates
  value: platform.inventory.system-profile
- name: NUMBER_OF_KAFKA_SYSTEM_PROFILE_TOPIC_PARTITIONS
  description: Number of partitions for the Kafka system-profile topic
  value: '1'
- name: KAFKA_KESSEL_WORKSPACES_TOPIC
  description: The Kafka topic for Kessel Workspace data
  value: outbox.event.workspace
- name: NUMBER_OF_KAFKA_KESSEL_WORKSPACES_TOPIC_PARTITIONS
  description: Number of partitions for the Kafka kessel workspaces topic
  value: '1'
- name: PAYLOAD_TRACKER_KAFKA_TOPIC
  description: The topic for payload tracker
  value: platform.payload-status
- name: NUMBER_OF_PAYLOAD_TRACKER_KAFKA_TOPIC_PARTITIONS
  description: Number of partitions for the payload tracker topic.
  value: '1'
- name: KAFKA_EXPORT_SERVICE_TOPIC
  description: The topic used to consume Export Service data
  value: platform.export.requests
- name: NUMBER_OF_KAFKA_EXPORT_SERVICE_TOPIC_PARTITIONS
  description: Number of partitions for the export-service topic
  value: '1'
- name: KAFKA_ADDITIONAL_VALIDATION_TOPIC
  description: Used by system_profile_validator
  value: platform.inventory.host-ingress-p1
- name: KAFKA_HOST_APP_DATA_TOPIC
  description: The topic for host application data from downstream services
  value: platform.inventory.host-apps
- name: KAFKA_HOST_APP_DATA_GROUP
  description: The Kafka consumer group for host app data consumer
  value: inventory-views
- name: NUMBER_OF_KAFKA_HOST_APP_DATA_TOPIC_PARTITIONS
  description: Number of partitions for the Kafka host app data topic
  value: '1'

# -- Database Configuration --
- description: Database name
  name: DB_NAME
  value: host-inventory
- description: SSL validation mode for the DB
  name: INVENTORY_DB_SSL_MODE
  value: prefer
- name: INVENTORY_DB_SSL_CERT
  value: ''
- name: INVENTORY_DB_SCHEMA
  value: 'hbi'
- name: INVENTORY_DB_STATEMENT_TIMEOUT
  value: '30000'
- name: INVENTORY_DB_LOCK_TIMEOUT
  value: '30000'
- name: HOSTS_TABLE_NUM_PARTITIONS
  description: The number of partitions for the hosts table
  value: '1'
- name: MIGRATION_MODE
  description: Choose migration mode to run DB migrations
  required: true
  value: automated

# -- Feature Flags (Unleash) --
- description: Unleash secret name
  name: UNLEASH_SECRET_NAME
  value: bypass
- description: Unleash API url
  name: UNLEASH_URL
- description: disable Unleash (feature flags), defaulting to fallback values
  name: BYPASS_UNLEASH
  value: 'false'
- description: How frequently the Unleash client refreshes data from the server (in seconds)
  name: UNLEASH_REFRESH_INTERVAL
  value: "15"

# -- Other Services & General Config --
- name: PATH_PREFIX
  value: api
- name: CONSOLEDOT_HOSTNAME
  value: localhost
- name: PROMETHEUS_PUSHGATEWAY
  value: 'localhost:9091'
- name: URLLIB3_LOG_LEVEL
  value: WARNING
- name: CONNEXION_LOG_LEVEL
  value: WARNING
- description: disable RBAC middleware
  name: BYPASS_RBAC
  value: 'false'
- description: disable Kessel middleware
  name: BYPASS_KESSEL
  value: 'false'
- description: enable Kessel authentication
  name: KESSEL_AUTH_ENABLED
  value: 'false'
- description: enable Kessel insecure mode
  name: KESSEL_INSECURE
  value: 'true'
- description: How long to wait for DB migrations to complete
  name: WAIT_FOR_MIGRATIONS_TIMEOUT_SECONDS
  value: '300'

# =================================================================================
# IV. Application Behavior & Tuning
# =================================================================================

# -- Gunicorn Web Server --
- name: GUNICORN_WORKERS
  value: '4'
- name: GUNICORN_THREADS
  value: '8'
- name: GUNICORN_REQUEST_FIELD_LIMIT
  value: '16380'
- name: GUNICORN_REQUEST_LINE_LIMIT
  value: '8190'

# -- API Probes --
- name: INVENTORY_API_WRITES_LIVENESS_PROBE_PERIOD_SECONDS
  value: '30'
- name: INVENTORY_API_WRITES_LIVENESS_PROBE_TIMEOUT_SECONDS
  value: '60'
- name: INVENTORY_API_WRITES_READINESS_PROBE_PERIOD_SECONDS
  value: '30'
- name: INVENTORY_API_WRITES_READINESS_PROBE_TIMEOUT_SECONDS
  value: '60'
- name: INVENTORY_API_READS_LIVENESS_PROBE_PERIOD_SECONDS
  value: '30'
- name: INVENTORY_API_READS_LIVENESS_PROBE_TIMEOUT_SECONDS
  value: '60'
- name: INVENTORY_API_READS_READINESS_PROBE_PERIOD_SECONDS
  value: '30'
- name: INVENTORY_API_READS_READINESS_PROBE_TIMEOUT_SECONDS
  value: '60'

# -- Caching --
- name: INVENTORY_API_CACHE_TYPE
  value: 'NullCache'
- name: INVENTORY_API_CACHE_TIMEOUT_SECONDS
  value: '0'
- name: INVENTORY_CACHE_INSIGHTS_CLIENT_SYSTEM_TIMEOUT_SEC
  value: '129600'
- name: INVENTORY_CACHE_THREAD_POOL_MAX_WORKERS
  value: '5'

# -- Read Replicas --
- name: INVENTORY_API_USE_READREPLICA
  value: 'false'
- name: INVENTORY_API_READREPLICA_SECRET
  value: 'host-inventory-read-only-db'
- name: INVENTORY_API_SECONDARY_READREPLICA_SECRET
  value: 'host-inventory-read-only-db'

# -- Batch & Processing Sizes --
- name: MQ_DB_BATCH_MAX_MESSAGES
  value: '1'
- name: MQ_WORKSPACES_DB_BATCH_MAX_MESSAGES
  value: '1'
- name: MQ_HOST_APP_DATA_DB_BATCH_MAX_MESSAGES
  value: '1'
- name: MQ_DB_BATCH_MAX_SECONDS
  value: '0.5'
- name: SCRIPT_CHUNK_SIZE
  value: '500'

# -- General Behavior --
- name: REBUILD_EVENTS_TIME_LIMIT
  value: '3600'
- name: CONSUMER_MQ_BROKER
  value: ''
- name: REPLICA_NAMESPACE
  description: Disable Kafka operations in the replica namespace
  value: 'false'

# =================================================================================
# V. Job-Specific Configuration
# =================================================================================

# -- Reaper Job --
- name: REAPER_SUSPEND
  value: 'true'
- name: HOST_DELETE_CHUNK_SIZE
  value: "1000"

# -- Stale Host Notification Job --
- name: STALE_HOST_NOTIFICATION_SUSPEND
  value: 'true'
- name: STALE_HOST_NOTIFICATION_SCHEDULE
  value: '*/1 * * * *'

# -- System Profile Validator Job --
- name: SP_VALIDATOR_SUSPEND
  value: 'true'
- name: KAFKA_SP_VALIDATOR_MAX_MESSAGES
  value: '10000'

# -- Pendo Syncher Job --
- name: PENDO_SYNCHER_SUSPEND
  value: 'true'
- name: PENDO_CRON_SCHEDULE
  value: '@daily'
- name: PENDO_SYNC_ACTIVE
  value: 'false'

# -- Syndicator Job (Logical Replication) --
- name: SYNDICATOR_SUSPEND
  value: 'false'
- name: SYNDICATOR_CRON_SCHEDULE
  value: '*/5 * * * *'
- name: SYNDICATOR_CREATE_PUBLICATIONS
  description: Publications to create
  value: ''
- name: SYNDICATOR_DROP_PUBLICATIONS
  description: Publications to drop
  value: ''
- name: SYNDICATOR_DROP_REPLICATION_SLOTS
  description: Replication slots to drop
  value: ''
- name: SYNDICATOR_REPLICA_IDENTITY_MODE
  description: Replica Identity Mode to set in the published tables (and their partitions)
  value: ''

# -- Delete Hosts from S3 Job --
- name: DELETE_HOSTS_S3_AWS_SECRET
  description: The AWS secret for the delete-hosts S3 bucket
  value: 'hbi-delete-host-ids-s3'
- name: DELETE_HOSTS_DRY_RUN
  description: Whether the delete_hosts_s3 script should run in dry-run mode
  value: 'true'
- name: DELETE_HOSTS_S3_BATCH_SIZE
  description: The batch size to use for the delete-hosts-s3 script.
  value: '500'
- name: SUSPEND_DELETE_HOSTS_S3
  description: If set to true, the delete-hosts-s3 job will immediately exit upon running.
  value: 'true'

# -- Duplicate Hosts Remover Job --
- name: REMOVE_DUPLICATES_DRY_RUN
  description: Whether the duplicate hosts remover script should run in dry-run mode
  value: 'true'
- name: SUSPEND_DUPLICATE_HOSTS_REMOVER
  description: If set to true, the duplicate-hosts-remover job will immediately exit upon running.
  value: 'true'

# -- Ungrouped Hosts Jobs --
- name: CREATE_UNGROUPED_GROUPS_BATCH_SIZE
  description: The batch size to use for the create-ungrouped-groups script.
  value: '100'
- name: ASSIGN_UNGROUPED_GROUPS_BATCH_SIZE
  description: The batch size to use for the assign-ungrouped-hosts script.
  value: '10'

# -- Update RHSM host timestamps Job --
- name: UPDATE_RHSM_HOST_TIMESTAMPS_DRY_RUN
  description: Whether the update-rhsm-host-timestamps script should run in dry-run mode
  value: 'true'

# -- Backfill per-reporter culled timestamps Job --
- name: BACKFILL_PER_REPORTER_CULLED_TIMESTAMPS_DRY_RUN
  description: Whether the backfill-per-reporter-culled-timestamps script should run in dry-run mode
  value: 'true'

# -- Populate host_type Job --
- name: POPULATE_HOST_TYPE_DRY_RUN
  description: Whether the populate-host-type script should run in dry-run mode
  value: 'true'
- name: POPULATE_HOST_TYPE_SUSPEND_JOB
  description: Whether the populate-host-type job should be suspended
  value: 'true'
- name: POPULATE_HOST_TYPE_BATCH_SIZE
  description: Number of hosts to process per batch in the populate-host-type job
  value: '500'

# =================================================================================
# VI. Floorist Configuration
# =================================================================================
# Settings for the Floorist metrics exporter.

- name: FLOORIST_SUSPEND
  description: Disable Floorist cronjob execution
  required: true
  value: 'true'
- description: bucket secret name
  name: FLOORIST_BUCKET_SECRET_NAME
  required: true
  value: dummy-secret
- description: bucket secret name for hms
  name: FLOORIST_HMS_BUCKET_SECRET_NAME
  required: true
  value: dummy-hms-secret
- name: FLOORIST_LOGLEVEL
  description: Floorist loglevel config
  value: 'INFO'
- name: FLOORIST_DB_SECRET_NAME
  description: database secret name
  value: host-inventory-db
