apiVersion: v1
kind: Template
metadata:
  name: insights-host-inventory
objects:
- apiVersion: cloud.redhat.com/v1alpha1
  kind: ClowdApp
  metadata:
    name: ${CLOWDAPP_NAME}
  spec:
    envName: ${ENV_NAME}
    featureFlags: true
    testing:
      iqePlugin: host-inventory
    dependencies:
      - rbac
      - xjoin-search
      - ingress
    deployments:
    - name: service
      minReplicas: ${{REPLICAS_SVC}}
      webServices:
        public:
          enabled: true
          apiPath: inventory
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        command:
        - gunicorn
        - --workers=${GUNICORN_WORKERS}
        - --threads=${GUNICORN_THREADS}
        - --limit-request-field_size=${GUNICORN_REQUEST_FIELD_LIMIT}
        - --limit-request-line=${GUNICORN_REQUEST_LINE_LIMIT}
        - --worker-tmp-dir=/gunicorn
        - -c
        - gunicorn.conf.py
        - -b
        - 0.0.0.0:8000
        - -t
        - '60'
        - run
        env:
        - name: APP_NAME
          value: ${APP_NAME}
        - name: PATH_PREFIX
          value: ${PATH_PREFIX}
        - name: INVENTORY_LEGACY_API_URL
          value: /r/insights/platform/inventory/v1/
        - name: prometheus_multiproc_dir
          value: /tmp/inventory/prometheus
        - name: INVENTORY_LOG_LEVEL
          value: ${LOG_LEVEL}
        - name: URLLIB3_LOG_LEVEL
          value: ${URLLIB3_LOG_LEVEL}
        - name: INVENTORY_DB_SSL_MODE
          value: ${INVENTORY_DB_SSL_MODE}
        - name: PAYLOAD_TRACKER_SERVICE_NAME
          value: inventory
        - name: PAYLOAD_TRACKER_ENABLED
          value: 'true'
        - name: XJOIN_GRAPHQL_URL
          value: http://${XJOIN_SEARCH_HOST}:${XJOIN_SEARCH_PORT}/graphql
        - name: BYPASS_RBAC
          value: ${BYPASS_RBAC}
        - name: KAFKA_PRODUCER_ACKS
          value: ${KAFKA_PRODUCER_ACKS}
        - name: KAFKA_PRODUCER_RETRIES
          value: ${KAFKA_PRODUCER_RETRIES}
        - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
          value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
        - name: KAFKA_SECURITY_PROTOCOL
          value: ${KAFKA_SECURITY_PROTOCOL}
        - name: KAFKA_SASL_MECHANISM
          value: ${KAFKA_SASL_MECHANISM}
        - name: KAFKA_EVENT_TOPIC
          value: ${KAFKA_EVENT_TOPIC}
        - name: KAFKA_NOTIFICATION_TOPIC
          value: ${KAFKA_NOTIFICATION_TOPIC}
        - name: TENANT_TRANSLATOR_URL
          value: http://${TENANT_TRANSLATOR_HOST}:${TENANT_TRANSLATOR_PORT}/internal/orgIds
        - name: BYPASS_TENANT_TRANSLATION
          value: ${BYPASS_TENANT_TRANSLATION}
        - name: CLOWDER_ENABLED
          value: "true"
        - name: UNLEASH_URL
          value: ${UNLEASH_URL}
        - name: UNLEASH_TOKEN
          valueFrom:
            secretKeyRef:
              name: ${UNLEASH_SECRET_NAME}
              key: CLIENT_ACCESS_TOKEN
              optional: true
        - name: BYPASS_UNLEASH
          value: ${BYPASS_UNLEASH}
        resources:
          limits:
            cpu: ${CPU_LIMIT}
            memory: ${MEMORY_LIMIT}
          requests:
            cpu: ${CPU_REQUEST}
            memory: ${MEMORY_REQUEST}
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /health
            port: 8000
            scheme: HTTP
          periodSeconds: 30
          successThreshold: 1
          timeoutSeconds: 60
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /health
            port: 8000
            scheme: HTTP
          periodSeconds: 30
          successThreshold: 1
          timeoutSeconds: 60
        volumeMounts:
        - mountPath: /tmp/inventory/prometheus
          name: prometheus-volume
        - mountPath: /gunicorn
          name: gunicorn-worker-dir
        volumes:
        - emptyDir: {}
          name: prometheus-volume
        - emptyDir:
            medium: Memory
          name: gunicorn-worker-dir
    - name: mq-pmin
      minReplicas: ${{REPLICAS_PMIN}}
      podSpec:
        command:
        - /bin/sh
        - -c
        - python inv_mq_service.py
        env:
        - name: INVENTORY_LOG_LEVEL
          value: ${LOG_LEVEL}
        - name: INVENTORY_DB_SSL_MODE
          value: ${INVENTORY_DB_SSL_MODE}
        - name: INVENTORY_DB_SSL_CERT
          value: ${INVENTORY_DB_SSL_CERT}
        - name: KAFKA_CONSUMER_TOPIC
          value: ${KAFKA_HOST_INGRESS_TOPIC}
        - name: KAFKA_HOST_INGRESS_TOPIC
          value: ${KAFKA_HOST_INGRESS_TOPIC}
        - name: KAFKA_EVENT_TOPIC
          value: ${KAFKA_EVENT_TOPIC}
        - name: KAFKA_NOTIFICATION_TOPIC
          value: ${KAFKA_NOTIFICATION_TOPIC}
        - name: KAFKA_SYSTEM_PROFILE_TOPIC
          value: ${KAFKA_SYSTEM_PROFILE_TOPIC}
        - name: KAFKA_HOST_INGRESS_GROUP
          value: ${KAFKA_HOST_INGRESS_GROUP}
        - name: PAYLOAD_TRACKER_SERVICE_NAME
          value: inventory-mq-service
        - name: PAYLOAD_TRACKER_ENABLED
          value: 'true'
        - name: KAFKA_PRODUCER_ACKS
          value: ${KAFKA_PRODUCER_ACKS}
        - name: KAFKA_PRODUCER_RETRIES
          value: ${KAFKA_PRODUCER_RETRIES}
        - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
          value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
        - name: KAFKA_SECURITY_PROTOCOL
          value: ${KAFKA_SECURITY_PROTOCOL}
        - name: KAFKA_SASL_MECHANISM
          value: ${KAFKA_SASL_MECHANISM}
        - name: TENANT_TRANSLATOR_URL
          value: http://${TENANT_TRANSLATOR_HOST}:${TENANT_TRANSLATOR_PORT}/internal/orgIds
        - name: BYPASS_TENANT_TRANSLATION
          value: ${BYPASS_TENANT_TRANSLATION}
        - name: CLOWDER_ENABLED
          value: "true"
        - name: UNLEASH_URL
          value: ${UNLEASH_URL}
        - name: UNLEASH_TOKEN
          valueFrom:
            secretKeyRef:
              name: ${UNLEASH_SECRET_NAME}
              key: CLIENT_ACCESS_TOKEN
              optional: true
        - name: BYPASS_UNLEASH
          value: ${BYPASS_UNLEASH}
        image: ${IMAGE}:${IMAGE_TAG}
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /
            port: 9000
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        readinessProbe:
          tcpSocket:
            port: 9000
        resources:
          limits:
            cpu: ${CPU_LIMIT}
            memory: ${MEMORY_LIMIT}
          requests:
            cpu: ${CPU_REQUEST}
            memory: ${MEMORY_REQUEST}
    - name: mq-p1
      minReplicas: ${{REPLICAS_P1}}
      podSpec:
        initContainers:
        - command:
          - /bin/sh
          - -c
          - python manage.py db upgrade
          inheritEnv: true
        command:
        - /bin/sh
        - -c
        - python inv_mq_service.py
        env:
        - name: INVENTORY_LOG_LEVEL
          value: ${LOG_LEVEL}
        - name: INVENTORY_DB_SSL_MODE
          value: ${INVENTORY_DB_SSL_MODE}
        - name: INVENTORY_DB_SSL_CERT
          value: ${INVENTORY_DB_SSL_CERT}
        - name: KAFKA_CONSUMER_TOPIC
          value: ${KAFKA_HOST_INGRESS_P1_TOPIC}
        - name: KAFKA_HOST_INGRESS_TOPIC
          value: ${KAFKA_HOST_INGRESS_P1_TOPIC}
        - name: KAFKA_EVENT_TOPIC
          value: ${KAFKA_EVENT_TOPIC}
        - name: KAFKA_NOTIFICATION_TOPIC
          value: ${KAFKA_NOTIFICATION_TOPIC}
        - name: KAFKA_SYSTEM_PROFILE_TOPIC
          value: ${KAFKA_SYSTEM_PROFILE_TOPIC}
        - name: KAFKA_HOST_INGRESS_GROUP
          value: ${KAFKA_HOST_INGRESS_GROUP}
        - name: PAYLOAD_TRACKER_SERVICE_NAME
          value: inventory-mq-service
        - name: PAYLOAD_TRACKER_ENABLED
          value: 'true'
        - name: KAFKA_PRODUCER_ACKS
          value: ${KAFKA_PRODUCER_ACKS}
        - name: KAFKA_PRODUCER_RETRIES
          value: ${KAFKA_PRODUCER_RETRIES}
        - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
          value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
        - name: KAFKA_SECURITY_PROTOCOL
          value: ${KAFKA_SECURITY_PROTOCOL}
        - name: KAFKA_SASL_MECHANISM
          value: ${KAFKA_SASL_MECHANISM}
        - name: TENANT_TRANSLATOR_URL
          value: http://${TENANT_TRANSLATOR_HOST}:${TENANT_TRANSLATOR_PORT}/internal/orgIds
        - name: BYPASS_TENANT_TRANSLATION
          value: ${BYPASS_TENANT_TRANSLATION}
        - name: CLOWDER_ENABLED
          value: "true"
        - name: UNLEASH_URL
          value: ${UNLEASH_URL}
        - name: UNLEASH_TOKEN
          valueFrom:
            secretKeyRef:
              name: ${UNLEASH_SECRET_NAME}
              key: CLIENT_ACCESS_TOKEN
              optional: true
        - name: BYPASS_UNLEASH
          value: ${BYPASS_UNLEASH}
        image: ${IMAGE}:${IMAGE_TAG}
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /
            port: 9000
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        readinessProbe:
          tcpSocket:
            port: 9000
        resources:
          limits:
            cpu: ${CPU_LIMIT}
            memory: ${MEMORY_LIMIT}
          requests:
            cpu: ${CPU_REQUEST}
            memory: ${MEMORY_REQUEST}
    - name: mq-sp
      minReplicas: ${{REPLICAS_SP}}
      podSpec:
        command:
        - /bin/sh
        - -c
        - python inv_mq_service.py
        env:
        - name: INVENTORY_LOG_LEVEL
          value: ${LOG_LEVEL}
        - name: INVENTORY_DB_SSL_MODE
          value: ${INVENTORY_DB_SSL_MODE}
        - name: INVENTORY_DB_SSL_CERT
          value: ${INVENTORY_DB_SSL_CERT}
        - name: KAFKA_CONSUMER_TOPIC
          value: ${KAFKA_SYSTEM_PROFILE_TOPIC}
        - name: KAFKA_HOST_INGRESS_TOPIC
          value: ${KAFKA_HOST_INGRESS_TOPIC}
        - name: KAFKA_EVENT_TOPIC
          value: ${KAFKA_EVENT_TOPIC}
        - name: KAFKA_NOTIFICATION_TOPIC
          value: ${KAFKA_NOTIFICATION_TOPIC}
        - name: KAFKA_SYSTEM_PROFILE_TOPIC
          value: ${KAFKA_SYSTEM_PROFILE_TOPIC}
        - name: KAFKA_HOST_INGRESS_GROUP
          value: ${KAFKA_HOST_INGRESS_GROUP}
        - name: PAYLOAD_TRACKER_SERVICE_NAME
          value: inventory-mq-service
        - name: PAYLOAD_TRACKER_ENABLED
          value: 'true'
        - name: KAFKA_PRODUCER_ACKS
          value: ${KAFKA_PRODUCER_ACKS}
        - name: KAFKA_PRODUCER_RETRIES
          value: ${KAFKA_PRODUCER_RETRIES}
        - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
          value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
        - name: KAFKA_SECURITY_PROTOCOL
          value: ${KAFKA_SECURITY_PROTOCOL}
        - name: KAFKA_SASL_MECHANISM
          value: ${KAFKA_SASL_MECHANISM}
        - name: TENANT_TRANSLATOR_URL
          value: http://${TENANT_TRANSLATOR_HOST}:${TENANT_TRANSLATOR_PORT}/internal/orgIds
        - name: BYPASS_TENANT_TRANSLATION
          value: ${BYPASS_TENANT_TRANSLATION}
        - name: CLOWDER_ENABLED
          value: "true"
        - name: UNLEASH_URL
          value: ${UNLEASH_URL}
        - name: UNLEASH_TOKEN
          valueFrom:
            secretKeyRef:
              name: ${UNLEASH_SECRET_NAME}
              key: CLIENT_ACCESS_TOKEN
              optional: true
        - name: BYPASS_UNLEASH
          value: ${BYPASS_UNLEASH}
        image: ${IMAGE}:${IMAGE_TAG}
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /
            port: 9000
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        readinessProbe:
          tcpSocket:
            port: 9000
        resources:
          limits:
            cpu: ${CPU_LIMIT}
            memory: ${MEMORY_LIMIT}
          requests:
            cpu: ${CPU_REQUEST}
            memory: ${MEMORY_REQUEST}
    jobs:
    - name: reaper
      schedule: '@hourly'
      suspend: ${{REAPER_SUSPEND}}
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        restartPolicy: Never
        command:
          - /bin/sh
          - -c
          - python host_reaper.py
        env:
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
          - name: PAYLOAD_TRACKER_KAFKA_TOPIC
            value: platform.payload-status
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory-mq-service
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - name: CLOWDER_ENABLED
            value: "true"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - name: UNLEASH_TOKEN
            valueFrom:
              secretKeyRef:
                name: ${UNLEASH_SECRET_NAME}
                key: CLIENT_ACCESS_TOKEN
                optional: true
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
        resources:
          limits:
            cpu: ${CPU_LIMIT}
            memory: ${MEMORY_LIMIT_REAPER}
          requests:
            cpu: ${CPU_REQUEST}
            memory: ${MEMORY_REQUEST_REAPER}
    - name: sp-validator
      schedule: '@hourly'
      suspend: ${{SP_VALIDATOR_SUSPEND}}
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        restartPolicy: Never
        command:
          - /bin/sh
          - -c
          - python system_profile_validator.py
        env:
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: GIT_TOKEN
            valueFrom:
              secretKeyRef:
                key: token
                name: dippy-bot
          - name: GIT_USER
            valueFrom:
              secretKeyRef:
                key: user
                name: dippy-bot
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
          - name: PAYLOAD_TRACKER_KAFKA_TOPIC
            value: platform.payload-status
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory-mq-service
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: KAFKA_CONSUMER_TOPIC
            value: ${KAFKA_HOST_INGRESS_TOPIC}
          - name: KAFKA_HOST_INGRESS_TOPIC
            value: ${KAFKA_HOST_INGRESS_TOPIC}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: KAFKA_SYSTEM_PROFILE_TOPIC
            value: ${KAFKA_SYSTEM_PROFILE_TOPIC}
          - name: KAFKA_ADDITIONAL_VALIDATION_TOPIC
            value: ${KAFKA_ADDITIONAL_VALIDATION_TOPIC}
          - name: KAFKA_SP_VALIDATOR_MAX_MESSAGES
            value: ${KAFKA_SP_VALIDATOR_MAX_MESSAGES}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - name: CLOWDER_ENABLED
            value: "true"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - name: UNLEASH_TOKEN
            valueFrom:
              secretKeyRef:
                name: ${UNLEASH_SECRET_NAME}
                key: CLIENT_ACCESS_TOKEN
                optional: true
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
        resources:
          limits:
            cpu: ${CPU_LIMIT}
            memory: ${MEMORY_LIMIT}
          requests:
            cpu: ${CPU_REQUEST}
            memory: ${MEMORY_REQUEST}
    - name: pendo-syncher
      schedule: ${PENDO_CRON_SCHEDULE}
      suspend: ${{PENDO_SYNCHER_SUSPEND}}
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        restartPolicy: Never
        command:
          - /bin/sh
          - -c
          - python pendo_syncher.py
        env:
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: PENDO_SYNC_ACTIVE
            value: ${PENDO_SYNC_ACTIVE}
          - name: PENDO_INTEGRATION_KEY
            valueFrom:
              secretKeyRef:
                key: apikey
                name: pendo-creds
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CLOWDER_ENABLED
            value: "true"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - name: UNLEASH_TOKEN
            valueFrom:
              secretKeyRef:
                name: ${UNLEASH_SECRET_NAME}
                key: CLIENT_ACCESS_TOKEN
                optional: true
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
        resources:
          limits:
            cpu: ${CPU_LIMIT}
            memory: ${MEMORY_LIMIT}
          requests:
            cpu: ${CPU_REQUEST}
            memory: ${MEMORY_REQUEST}
    - name: synchronizer
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        restartPolicy: OnFailure
        command:
          - /bin/sh
          - -c
          - python host_synchronizer.py
        env:
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: PAYLOAD_TRACKER_KAFKA_TOPIC
            value: platform.payload-status
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory-mq-service
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - name: CLOWDER_ENABLED
            value: "true"
          - name: SCRIPT_CHUNK_SIZE
            value: ${SCRIPT_CHUNK_SIZE}
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - name: UNLEASH_TOKEN
            valueFrom:
              secretKeyRef:
                name: ${UNLEASH_SECRET_NAME}
                key: CLIENT_ACCESS_TOKEN
                optional: true
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
        resources:
          limits:
            cpu: ${CPU_LIMIT}
            memory: ${MEMORY_LIMIT_SYNC}
          requests:
            cpu: ${CPU_REQUEST}
            memory: ${MEMORY_REQUEST_SYNC}
    database:
      name: ${DB_NAME}
      version: 12
    kafkaTopics:
      - topicName: ${KAFKA_SYSTEM_PROFILE_TOPIC}
        partitions: 1
      - topicName: platform.payload-status
        partitions: 1
      - topicName: ${KAFKA_EVENT_TOPIC}
        partitions: 1
      - topicName: ${KAFKA_NOTIFICATION_TOPIC}
        partitions: 1
      - topicName: ${KAFKA_HOST_INGRESS_TOPIC}
        partitions: 1
      - topicName: ${KAFKA_HOST_INGRESS_P1_TOPIC}
        partitions: 1
# this service proxies requests for the old URL (insights-inventory:8080) to the clowderized service (host-inventory-service:8000)
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app: insights-inventory
    name: insights-inventory
  spec:
    ports:
    - name: port-8080
      port: 8080
      protocol: TCP
      targetPort: 8000
    selector:
      pod: host-inventory-service
- apiVersion: metrics.console.redhat.com/v1alpha1
  kind: FloorPlan
  metadata:
    name: host-inventory
  spec:
    database:
      secretName: ${FLOORIST_DB_SECRET_NAME}
    objectStore:
      secretName: ${FLOORIST_BUCKET_SECRET_NAME}
    suspend: ${{FLOORIST_SUSPEND}}
    logLevel: ${FLOORIST_LOGLEVEL}
    queries:
      - prefix: insights/inventory/hosts
        query: >-
          SELECT
            "id",
            "account" AS "account_number",
            "created_on" AS "created_at",
            "modified_on" AS "updated_at",
            "ansible_host" AS "ansible_host",
            CONCAT_WS('.',"system_profile_facts"->'operating_system'->>'name',"system_profile_facts"->'operating_system'->'major',"system_profile_facts"->'operating_system'->'minor') AS "os_version",
            "system_profile_facts"->'host_type' AS "host_type",
            "system_profile_facts"->'ansible'->'controller_version' AS "ansible_controller_version",
            "system_profile_facts"->'ansible'->'hub_version' AS "ansible_hub_version",
            "system_profile_facts"->'rhsm'->'version' AS "rhsm_version",
            "system_profile_facts"->'is_marketplace' AS "is_marketplace_installation",
            "system_profile_facts"->'insights_client_version' AS "insights_client_version",
            "system_profile_facts"->'insights_egg_version' AS "insights_egg_version",
            "system_profile_facts"->'satellite_managed' AS "is_satellite_managed",
            "system_profile_facts"->'subscription_status' AS "subscription_status",
            "system_profile_facts"->'ansible' AS "ansible_workload",
            "system_profile_facts"->'mssql' AS "mssql_workload",
            "system_profile_facts"->'sap' AS "sap_workload"
          FROM "hosts"
parameters:
- name: LOG_LEVEL
  value: INFO
- descrpition: Cpu request of service
  name: CPU_REQUEST
  value: 250m
- description: Cpu limit of service
  name: CPU_LIMIT
  value: 500m
- description: memory limit of service
  name: MEMORY_LIMIT
  value: 512Mi
- description: memory limit of host-synchronizer
  name: MEMORY_LIMIT_SYNC
  value: 3Gi
- description: memory limit of reaper
  name: MEMORY_LIMIT_REAPER
  value: 512Mi
- description: request limit for service
  name: MEMORY_REQUEST
  value: 256Mi
- description: request limit for reaper
  name: MEMORY_REQUEST_REAPER
  value: 256Mi
- description: request limit for host-synchronizer
  name: MEMORY_REQUEST_SYNC
  value: 3Gi
- description: Replica count for p1 consumer
  name: REPLICAS_P1
  value: "5"
- description: Replica count for pmin consumer
  name: REPLICAS_PMIN
  value: "3"
- description: Replica count for sp consumer
  name: REPLICAS_SP
  value: "2"
- description: Replica count for webservice
  name: REPLICAS_SVC
  value: "10"
- description: Image tag
  name: IMAGE_TAG
  required: true
- description: Image NAME
  name: IMAGE
  required: true
  value: quay.io/cloudservices/insights-inventory
- description : ClowdEnvironment name
  name: ENV_NAME
  value: stage
- name: APP_NAME
  value: inventory
- description: ClowdApp name
  name: CLOWDAPP_NAME
  value: host-inventory
- description: Database name
  name: DB_NAME
  value: host-inventory
- name: PATH_PREFIX
  value: api
- name: URLLIB3_LOG_LEVEL
  value: WARNING
- name: XJOIN_SEARCH_HOST
  value: localhost
- name: XJOIN_SEARCH_PORT
  value: '4000'
- description: SSL validation mode for the DB
  name: INVENTORY_DB_SSL_MODE
  value: prefer
- description: disable RBAC middleware
  name: BYPASS_RBAC
  value: 'false'
- description: disable account-to-org_id translation, defaulting to None where org_id is not provided
  name: BYPASS_TENANT_TRANSLATION
  value: 'false'
- name: KAFKA_PRODUCER_ACKS
  value: '1'
- name: KAFKA_PRODUCER_RETRIES
  value: '0'
- name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
  value: '100'
- name: KAFKA_HOST_INGRESS_TOPIC
  description: The topic containing Host data sent by reporters
  value: platform.inventory.host-ingress
- name: KAFKA_HOST_INGRESS_P1_TOPIC
  description: The TOP-PRIORITY topic containing Host data sent by reporters
  value: platform.inventory.host-ingress-p1
- name: KAFKA_EVENT_TOPIC
  description: The topic for Host data that were processed by Inventory
  value: platform.inventory.events
- name: KAFKA_NOTIFICATION_TOPIC
  description: The topic containing messages to be sent as notifications
  value: platform.notifications.ingress
- name: KAFKA_ADDITIONAL_VALIDATION_TOPIC
  description: Used by system_profile_validator
  value: platform.inventory.host-ingress-p1
- name: KAFKA_SYSTEM_PROFILE_TOPIC
  description: The topic containing Host data for System Profile updates
  value: platform.inventory.system-profile
- name: KAFKA_HOST_INGRESS_GROUP
  description: The Kafka consumer group name
  value: inventory-mq
- name: KAFKA_SECURITY_PROTOCOL
  description: The Kafka Security Protocol
  value: PLAINTEXT
- name: KAFKA_SASL_MECHANISM
  value: 'PLAIN'
- name: PROMETHEUS_PUSHGATEWAY
  value: 'localhost:9091'
- name: KAFKA_BOOTSTRAP_HOST
  value: 'localhost'
- name: KAFKA_BOOTSTRAP_PORT
  value: '29092'
- name: INVENTORY_DB_SSL_CERT
  value: ''
- name: PENDO_SYNCHER_SUSPEND
  value: 'true'
- name: PENDO_CRON_SCHEDULE
  value: '@daily'
- name: PENDO_SYNC_ACTIVE
  value: 'false'
- name: SP_VALIDATOR_SUSPEND
  value: 'true'
- name: REAPER_SUSPEND
  value: 'true'
- name: KAFKA_SP_VALIDATOR_MAX_MESSAGES
  value: '10000'
- name: TENANT_TRANSLATOR_HOST
  value: 'gateway.3scale-dev.svc.cluster.local'
- name: TENANT_TRANSLATOR_PORT
  value: '8892'
- name: GUNICORN_WORKERS
  value: '4'
- name: GUNICORN_THREADS
  value: '8'
- name: GUNICORN_REQUEST_FIELD_LIMIT
  value: '16380'
- name: GUNICORN_REQUEST_LINE_LIMIT
  value: '8190'
- name: SCRIPT_CHUNK_SIZE
  value: '500'

# Feature flags
- description: Unleash secret name
  name: UNLEASH_SECRET_NAME
  value: bypass
- description: Unleash API url
  name: UNLEASH_URL
- description: disable Unleash (feature flags), defaulting to fallback values
  name: BYPASS_UNLEASH
  value: 'false'

#floorist
- name: MEMORY_LIMIT_FLOO
  value: 200Mi
- name: MEMORY_REQUEST_FLOO
  value: 100Mi
- name: CPU_LIMIT_FLOO
  value: 100m
- name: CPU_REQUEST_FLOO
  value: 50m
- name: FLOORIST_SUSPEND
  description: Disable Floorist cronjob execution
  required: true
  value: 'true'
- description: bucket secret name
  name: FLOORIST_BUCKET_SECRET_NAME
  required: true
  value: dummy-secret
- name: FLOORIST_LOGLEVEL
  description: Floorist loglevel config
  value: 'INFO'
- name: FLOORIST_DISABLED
  description: Determines whether to build the Floorist Job.
  value: 'false'
- name: FLOORIST_DB_SECRET_NAME
  description: database secret name
  value: host-inventory-db
