apiVersion: v1
kind: Template
metadata:
  name: insights-host-inventory
objects:
- apiVersion: cloud.redhat.com/v1alpha1
  kind: ClowdApp
  metadata:
    name: ${CLOWDAPP_NAME}
  spec:
    envName: ${ENV_NAME}
    featureFlags: true
    testing:
      iqePlugin: host-inventory
    dependencies:
      - rbac
      - xjoin-search
      - ingress
    deployments:
    - name: service
      minReplicas: ${{REPLICAS_SVC}}
      webServices:
        public:
          enabled: true
          apiPath: inventory
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        args: [
          "gunicorn",
          "--workers=${GUNICORN_WORKERS}",
          "--threads=${GUNICORN_THREADS}",
          "--limit-request-field_size=${GUNICORN_REQUEST_FIELD_LIMIT}",
          "--limit-request-line=${GUNICORN_REQUEST_LINE_LIMIT}",
          "--worker-tmp-dir=/gunicorn",
          "-c",
          "gunicorn.conf.py",
          "-b",
          "0.0.0.0:8000",
          "-t",
          "60",
          "run"
        ]
        env:
        - name: APP_NAME
          value: ${APP_NAME}
        - name: PATH_PREFIX
          value: ${PATH_PREFIX}
        - name: INVENTORY_LEGACY_API_URL
          value: /r/insights/platform/inventory/v1/
        - name: prometheus_multiproc_dir
          value: /tmp/inventory/prometheus
        - name: INVENTORY_LOG_LEVEL
          value: ${LOG_LEVEL}
        - name: URLLIB3_LOG_LEVEL
          value: ${URLLIB3_LOG_LEVEL}
        - name: INVENTORY_DB_SSL_MODE
          value: ${INVENTORY_DB_SSL_MODE}
        - name: PAYLOAD_TRACKER_SERVICE_NAME
          value: inventory
        - name: PAYLOAD_TRACKER_ENABLED
          value: 'true'
        - name: XJOIN_GRAPHQL_URL
          value: http://${XJOIN_SEARCH_HOST}:${XJOIN_SEARCH_PORT}/graphql
        - name: BYPASS_RBAC
          value: ${BYPASS_RBAC}
        - name: KAFKA_PRODUCER_ACKS
          value: ${KAFKA_PRODUCER_ACKS}
        - name: KAFKA_PRODUCER_RETRIES
          value: ${KAFKA_PRODUCER_RETRIES}
        - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
          value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
        - name: KAFKA_SECURITY_PROTOCOL
          value: ${KAFKA_SECURITY_PROTOCOL}
        - name: KAFKA_SASL_MECHANISM
          value: ${KAFKA_SASL_MECHANISM}
        - name: KAFKA_EVENT_TOPIC
          value: ${KAFKA_EVENT_TOPIC}
        - name: KAFKA_NOTIFICATION_TOPIC
          value: ${KAFKA_NOTIFICATION_TOPIC}
        - name: TENANT_TRANSLATOR_URL
          value: http://${TENANT_TRANSLATOR_HOST}:${TENANT_TRANSLATOR_PORT}/internal/orgIds
        - name: BYPASS_TENANT_TRANSLATION
          value: ${BYPASS_TENANT_TRANSLATION}
        - name: CLOWDER_ENABLED
          value: "true"
        - name: UNLEASH_URL
          value: ${UNLEASH_URL}
        - name: UNLEASH_TOKEN
          valueFrom:
            secretKeyRef:
              name: ${UNLEASH_SECRET_NAME}
              key: CLIENT_ACCESS_TOKEN
              optional: true
        - name: BYPASS_UNLEASH
          value: ${BYPASS_UNLEASH}
        - name: SEGMENTIO_WRITE_KEY
          valueFrom:
            secretKeyRef:
              name: segmentio
              key: WRITE_KEY
              optional: true
        resources:
          limits:
            cpu: ${CPU_LIMIT_SERVICE}
            memory: ${MEMORY_LIMIT_SERVICE}
          requests:
            cpu: ${CPU_REQUEST_SERVICE}
            memory: ${MEMORY_REQUEST_SERVICE}
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /health
            port: 8000
            scheme: HTTP
          periodSeconds: 30
          successThreshold: 1
          timeoutSeconds: 60
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /health
            port: 8000
            scheme: HTTP
          periodSeconds: 30
          successThreshold: 1
          timeoutSeconds: 60
        volumeMounts:
        - mountPath: /tmp/inventory/prometheus
          name: prometheus-volume
        - mountPath: /gunicorn
          name: gunicorn-worker-dir
        volumes:
        - emptyDir: {}
          name: prometheus-volume
        - emptyDir:
            medium: Memory
          name: gunicorn-worker-dir
    - name: mq-pmin
      minReplicas: ${{REPLICAS_PMIN}}
      podSpec:
        args: ["./inv_mq_service.py"]
        env:
        - name: INVENTORY_LOG_LEVEL
          value: ${LOG_LEVEL}
        - name: INVENTORY_DB_SSL_MODE
          value: ${INVENTORY_DB_SSL_MODE}
        - name: INVENTORY_DB_SSL_CERT
          value: ${INVENTORY_DB_SSL_CERT}
        - name: KAFKA_CONSUMER_TOPIC
          value: ${KAFKA_HOST_INGRESS_TOPIC}
        - name: KAFKA_HOST_INGRESS_TOPIC
          value: ${KAFKA_HOST_INGRESS_TOPIC}
        - name: KAFKA_EVENT_TOPIC
          value: ${KAFKA_EVENT_TOPIC}
        - name: KAFKA_NOTIFICATION_TOPIC
          value: ${KAFKA_NOTIFICATION_TOPIC}
        - name: KAFKA_SYSTEM_PROFILE_TOPIC
          value: ${KAFKA_SYSTEM_PROFILE_TOPIC}
        - name: KAFKA_HOST_INGRESS_GROUP
          value: ${KAFKA_HOST_INGRESS_GROUP}
        - name: PAYLOAD_TRACKER_SERVICE_NAME
          value: inventory-mq-service
        - name: PAYLOAD_TRACKER_ENABLED
          value: 'true'
        - name: KAFKA_PRODUCER_ACKS
          value: ${KAFKA_PRODUCER_ACKS}
        - name: KAFKA_PRODUCER_RETRIES
          value: ${KAFKA_PRODUCER_RETRIES}
        - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
          value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
        - name: KAFKA_SECURITY_PROTOCOL
          value: ${KAFKA_SECURITY_PROTOCOL}
        - name: KAFKA_SASL_MECHANISM
          value: ${KAFKA_SASL_MECHANISM}
        - name: TENANT_TRANSLATOR_URL
          value: http://${TENANT_TRANSLATOR_HOST}:${TENANT_TRANSLATOR_PORT}/internal/orgIds
        - name: BYPASS_TENANT_TRANSLATION
          value: ${BYPASS_TENANT_TRANSLATION}
        - name: CLOWDER_ENABLED
          value: "true"
        - name: UNLEASH_URL
          value: ${UNLEASH_URL}
        - name: UNLEASH_TOKEN
          valueFrom:
            secretKeyRef:
              name: ${UNLEASH_SECRET_NAME}
              key: CLIENT_ACCESS_TOKEN
              optional: true
        - name: BYPASS_UNLEASH
          value: ${BYPASS_UNLEASH}
        image: ${IMAGE}:${IMAGE_TAG}
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /
            port: 9000
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        readinessProbe:
          tcpSocket:
            port: 9000
        resources:
          limits:
            cpu: ${CPU_LIMIT_MQ_PMIN}
            memory: ${MEMORY_LIMIT_MQ_PMIN}
          requests:
            cpu: ${CPU_REQUEST_MQ_PMIN}
            memory: ${MEMORY_REQUEST_MQ_PMIN}
    - name: mq-p1
      minReplicas: ${{REPLICAS_P1}}
      podSpec:
        initContainers:
        - args: ["FLASK_APP=./manage.py", "flask", "db", "upgrade"]
          inheritEnv: true
        args: ["./inv_mq_service.py"]
        env:
        - name: INVENTORY_LOG_LEVEL
          value: ${LOG_LEVEL}
        - name: INVENTORY_DB_SSL_MODE
          value: ${INVENTORY_DB_SSL_MODE}
        - name: INVENTORY_DB_SSL_CERT
          value: ${INVENTORY_DB_SSL_CERT}
        - name: KAFKA_CONSUMER_TOPIC
          value: ${KAFKA_HOST_INGRESS_P1_TOPIC}
        - name: KAFKA_HOST_INGRESS_TOPIC
          value: ${KAFKA_HOST_INGRESS_P1_TOPIC}
        - name: KAFKA_EVENT_TOPIC
          value: ${KAFKA_EVENT_TOPIC}
        - name: KAFKA_NOTIFICATION_TOPIC
          value: ${KAFKA_NOTIFICATION_TOPIC}
        - name: KAFKA_SYSTEM_PROFILE_TOPIC
          value: ${KAFKA_SYSTEM_PROFILE_TOPIC}
        - name: KAFKA_HOST_INGRESS_GROUP
          value: ${KAFKA_HOST_INGRESS_GROUP}
        - name: PAYLOAD_TRACKER_SERVICE_NAME
          value: inventory-mq-service
        - name: PAYLOAD_TRACKER_ENABLED
          value: 'true'
        - name: KAFKA_PRODUCER_ACKS
          value: ${KAFKA_PRODUCER_ACKS}
        - name: KAFKA_PRODUCER_RETRIES
          value: ${KAFKA_PRODUCER_RETRIES}
        - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
          value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
        - name: KAFKA_SECURITY_PROTOCOL
          value: ${KAFKA_SECURITY_PROTOCOL}
        - name: KAFKA_SASL_MECHANISM
          value: ${KAFKA_SASL_MECHANISM}
        - name: TENANT_TRANSLATOR_URL
          value: http://${TENANT_TRANSLATOR_HOST}:${TENANT_TRANSLATOR_PORT}/internal/orgIds
        - name: BYPASS_TENANT_TRANSLATION
          value: ${BYPASS_TENANT_TRANSLATION}
        - name: CLOWDER_ENABLED
          value: "true"
        - name: UNLEASH_URL
          value: ${UNLEASH_URL}
        - name: UNLEASH_TOKEN
          valueFrom:
            secretKeyRef:
              name: ${UNLEASH_SECRET_NAME}
              key: CLIENT_ACCESS_TOKEN
              optional: true
        - name: BYPASS_UNLEASH
          value: ${BYPASS_UNLEASH}
        image: ${IMAGE}:${IMAGE_TAG}
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /
            port: 9000
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        readinessProbe:
          tcpSocket:
            port: 9000
        resources:
          limits:
            cpu: ${CPU_LIMIT_MQ_P1}
            memory: ${MEMORY_LIMIT_MQ_P1}
          requests:
            cpu: ${CPU_REQUEST_MQ_P1}
            memory: ${MEMORY_REQUEST_MQ_P1}
    - name: mq-sp
      minReplicas: ${{REPLICAS_SP}}
      podSpec:
        args: ["./inv_mq_service.py"]
        env:
        - name: INVENTORY_LOG_LEVEL
          value: ${LOG_LEVEL}
        - name: INVENTORY_DB_SSL_MODE
          value: ${INVENTORY_DB_SSL_MODE}
        - name: INVENTORY_DB_SSL_CERT
          value: ${INVENTORY_DB_SSL_CERT}
        - name: KAFKA_CONSUMER_TOPIC
          value: ${KAFKA_SYSTEM_PROFILE_TOPIC}
        - name: KAFKA_HOST_INGRESS_TOPIC
          value: ${KAFKA_HOST_INGRESS_TOPIC}
        - name: KAFKA_EVENT_TOPIC
          value: ${KAFKA_EVENT_TOPIC}
        - name: KAFKA_NOTIFICATION_TOPIC
          value: ${KAFKA_NOTIFICATION_TOPIC}
        - name: KAFKA_SYSTEM_PROFILE_TOPIC
          value: ${KAFKA_SYSTEM_PROFILE_TOPIC}
        - name: KAFKA_HOST_INGRESS_GROUP
          value: ${KAFKA_HOST_INGRESS_GROUP}
        - name: PAYLOAD_TRACKER_SERVICE_NAME
          value: inventory-mq-service
        - name: PAYLOAD_TRACKER_ENABLED
          value: 'true'
        - name: KAFKA_PRODUCER_ACKS
          value: ${KAFKA_PRODUCER_ACKS}
        - name: KAFKA_PRODUCER_RETRIES
          value: ${KAFKA_PRODUCER_RETRIES}
        - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
          value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
        - name: KAFKA_SECURITY_PROTOCOL
          value: ${KAFKA_SECURITY_PROTOCOL}
        - name: KAFKA_SASL_MECHANISM
          value: ${KAFKA_SASL_MECHANISM}
        - name: TENANT_TRANSLATOR_URL
          value: http://${TENANT_TRANSLATOR_HOST}:${TENANT_TRANSLATOR_PORT}/internal/orgIds
        - name: BYPASS_TENANT_TRANSLATION
          value: ${BYPASS_TENANT_TRANSLATION}
        - name: CLOWDER_ENABLED
          value: "true"
        - name: UNLEASH_URL
          value: ${UNLEASH_URL}
        - name: UNLEASH_TOKEN
          valueFrom:
            secretKeyRef:
              name: ${UNLEASH_SECRET_NAME}
              key: CLIENT_ACCESS_TOKEN
              optional: true
        - name: BYPASS_UNLEASH
          value: ${BYPASS_UNLEASH}
        image: ${IMAGE}:${IMAGE_TAG}
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /
            port: 9000
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        readinessProbe:
          tcpSocket:
            port: 9000
        resources:
          limits:
            cpu: ${CPU_LIMIT_MQ_SP}
            memory: ${MEMORY_LIMIT_MQ_SP}
          requests:
            cpu: ${CPU_REQUEST_MQ_SP}
            memory: ${MEMORY_REQUEST_MQ_SP}
    jobs:
    - name: reaper
      schedule: '@hourly'
      concurrencyPolicy: "Forbid"
      suspend: ${{REAPER_SUSPEND}}
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        restartPolicy: Never
        args: ["./host_reaper.py"]
        env:
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
          - name: PAYLOAD_TRACKER_KAFKA_TOPIC
            value: platform.payload-status
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory-mq-service
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - name: CLOWDER_ENABLED
            value: "true"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - name: UNLEASH_TOKEN
            valueFrom:
              secretKeyRef:
                name: ${UNLEASH_SECRET_NAME}
                key: CLIENT_ACCESS_TOKEN
                optional: true
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
        resources:
          limits:
            cpu: ${CPU_LIMIT_REAPER}
            memory: ${MEMORY_LIMIT_REAPER}
          requests:
            cpu: ${CPU_REQUEST_REAPER}
            memory: ${MEMORY_REQUEST_REAPER}
    - name: sp-validator
      schedule: '@hourly'
      suspend: ${{SP_VALIDATOR_SUSPEND}}
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        restartPolicy: Never
        args: ["./system_profile_validator.py"]
        env:
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: GIT_TOKEN
            valueFrom:
              secretKeyRef:
                key: token
                name: dippy-bot
          - name: GIT_USER
            valueFrom:
              secretKeyRef:
                key: user
                name: dippy-bot
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
          - name: PAYLOAD_TRACKER_KAFKA_TOPIC
            value: platform.payload-status
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory-mq-service
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: KAFKA_CONSUMER_TOPIC
            value: ${KAFKA_HOST_INGRESS_TOPIC}
          - name: KAFKA_HOST_INGRESS_TOPIC
            value: ${KAFKA_HOST_INGRESS_TOPIC}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: KAFKA_SYSTEM_PROFILE_TOPIC
            value: ${KAFKA_SYSTEM_PROFILE_TOPIC}
          - name: KAFKA_ADDITIONAL_VALIDATION_TOPIC
            value: ${KAFKA_ADDITIONAL_VALIDATION_TOPIC}
          - name: KAFKA_SP_VALIDATOR_MAX_MESSAGES
            value: ${KAFKA_SP_VALIDATOR_MAX_MESSAGES}
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - name: CLOWDER_ENABLED
            value: "true"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - name: UNLEASH_TOKEN
            valueFrom:
              secretKeyRef:
                name: ${UNLEASH_SECRET_NAME}
                key: CLIENT_ACCESS_TOKEN
                optional: true
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
        resources:
          limits:
            cpu: ${CPU_LIMIT_SP_VALIDATOR}
            memory: ${MEMORY_LIMIT_SP_VALIDATOR}
          requests:
            cpu: ${CPU_REQUEST_SP_VALIDATOR}
            memory: ${MEMORY_REQUEST_SP_VALIDATOR}
    - name: pendo-syncher
      schedule: ${PENDO_CRON_SCHEDULE}
      suspend: ${{PENDO_SYNCHER_SUSPEND}}
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        restartPolicy: Never
        args: ["./pendo_syncher.py"]
        env:
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: PENDO_SYNC_ACTIVE
            value: ${PENDO_SYNC_ACTIVE}
          - name: PENDO_INTEGRATION_KEY
            valueFrom:
              secretKeyRef:
                key: apikey
                name: pendo-creds
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CLOWDER_ENABLED
            value: "true"
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - name: UNLEASH_TOKEN
            valueFrom:
              secretKeyRef:
                name: ${UNLEASH_SECRET_NAME}
                key: CLIENT_ACCESS_TOKEN
                optional: true
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
        resources:
          limits:
            cpu: ${CPU_LIMIT_PENDO_SYNCHER}
            memory: ${MEMORY_LIMIT_PENDO_SYNCHER}
          requests:
            cpu: ${CPU_REQUEST_PENDO_SYNCHER}
            memory: ${MEMORY_REQUEST_PENDO_SYNCHER}
    - name: synchronizer
      podSpec:
        image: ${IMAGE}:${IMAGE_TAG}
        restartPolicy: OnFailure
        args: ["./rebuild_events_topic.py", "&&", "./host_synchronizer.py"]
        env:
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
          - name: KAFKA_EVENT_TOPIC
            value: ${KAFKA_EVENT_TOPIC}
          - name: KAFKA_NOTIFICATION_TOPIC
            value: ${KAFKA_NOTIFICATION_TOPIC}
          - name: PAYLOAD_TRACKER_KAFKA_TOPIC
            value: platform.payload-status
          - name: PAYLOAD_TRACKER_SERVICE_NAME
            value: inventory-mq-service
          - name: PAYLOAD_TRACKER_ENABLED
            value: 'true'
          - name: PROMETHEUS_PUSHGATEWAY
            value: ${PROMETHEUS_PUSHGATEWAY}
          - name: KAFKA_PRODUCER_ACKS
            value: ${KAFKA_PRODUCER_ACKS}
          - name: KAFKA_PRODUCER_RETRIES
            value: ${KAFKA_PRODUCER_RETRIES}
          - name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
            value: ${KAFKA_PRODUCER_RETRY_BACKOFF_MS}
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: KAFKA_SECURITY_PROTOCOL
            value: ${KAFKA_SECURITY_PROTOCOL}
          - name: KAFKA_SASL_MECHANISM
            value: ${KAFKA_SASL_MECHANISM}
          - name: CLOWDER_ENABLED
            value: "true"
          - name: SCRIPT_CHUNK_SIZE
            value: ${SCRIPT_CHUNK_SIZE}
          - name: UNLEASH_URL
            value: ${UNLEASH_URL}
          - name: UNLEASH_TOKEN
            valueFrom:
              secretKeyRef:
                name: ${UNLEASH_SECRET_NAME}
                key: CLIENT_ACCESS_TOKEN
                optional: true
          - name: BYPASS_UNLEASH
            value: ${BYPASS_UNLEASH}
          - name: REBUILD_EVENTS_TIME_LIMIT
            value: ${REBUILD_EVENTS_TIME_LIMIT}
        resources:
          limits:
            cpu: ${CPU_LIMIT_SYNCHRONIZER}
            memory: ${MEMORY_LIMIT_SYNCHRONIZER}
          requests:
            cpu: ${CPU_REQUEST_SYNCHRONIZER}
            memory: ${MEMORY_REQUEST_SYNCHRONIZER}
    - name: pg-repack
      schedule: ${PG_REPACK_SCHEDULE}
      concurrencyPolicy: "Forbid"
      suspend: ${{PG_REPACK_SUSPEND}}
      podSpec:
        image: ${PG_REPACK_IMAGE}:${IMAGE_TAG}
        restartPolicy: Never
        args: ["./run_pg_repack.py"]
        env:
          - name: INVENTORY_LOG_LEVEL
            value: ${LOG_LEVEL}
          - name: INVENTORY_DB_SSL_MODE
            value: ${INVENTORY_DB_SSL_MODE}
          - name: INVENTORY_DB_SSL_CERT
            value: ${INVENTORY_DB_SSL_CERT}
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CLOWDER_ENABLED
            value: "true"
        resources:
          limits:
            cpu: ${CPU_LIMIT_PG_REPACK}
            memory: ${MEMORY_LIMIT_PG_REPACK}
          requests:
            cpu: ${CPU_REQUEST_PG_REPACK}
            memory: ${MEMORY_REQUEST_PG_REPACK}
    database:
      name: ${DB_NAME}
      version: 13
    kafkaTopics:
      - topicName: ${KAFKA_SYSTEM_PROFILE_TOPIC}
        partitions: 1
      - topicName: platform.payload-status
        partitions: 1
      - topicName: ${KAFKA_EVENT_TOPIC}
        partitions: 1
      - topicName: ${KAFKA_NOTIFICATION_TOPIC}
        partitions: 1
      - topicName: ${KAFKA_HOST_INGRESS_TOPIC}
        partitions: 1
      - topicName: ${KAFKA_HOST_INGRESS_P1_TOPIC}
        partitions: 1
# this service proxies requests for the old URL (insights-inventory:8080) to the clowderized service (host-inventory-service:8000)
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app: insights-inventory
    name: insights-inventory
  spec:
    ports:
    - name: port-8080
      port: 8080
      protocol: TCP
      targetPort: 8000
    selector:
      pod: host-inventory-service
- apiVersion: metrics.console.redhat.com/v1alpha1
  kind: FloorPlan
  metadata:
    name: host-inventory
  spec:
    database:
      secretName: ${FLOORIST_DB_SECRET_NAME}
    objectStore:
      secretName: ${FLOORIST_BUCKET_SECRET_NAME}
    suspend: ${{FLOORIST_SUSPEND}}
    logLevel: ${FLOORIST_LOGLEVEL}
    queries:
      - prefix: insights/inventory/hosts
        query: >-
          SELECT
            "id",
            "account" AS "account_number",
            "created_on" AS "created_at",
            "modified_on" AS "updated_at",
            "ansible_host" AS "ansible_host",
            CONCAT_WS('.',"system_profile_facts"->'operating_system'->>'name',"system_profile_facts"->'operating_system'->'major',"system_profile_facts"->'operating_system'->'minor') AS "os_version",
            "system_profile_facts"->'host_type' AS "host_type",
            "system_profile_facts"->'ansible'->'controller_version' AS "ansible_controller_version",
            "system_profile_facts"->'ansible'->'hub_version' AS "ansible_hub_version",
            "system_profile_facts"->'rhsm'->'version' AS "rhsm_version",
            "system_profile_facts"->'is_marketplace' AS "is_marketplace_installation",
            "system_profile_facts"->'insights_client_version' AS "insights_client_version",
            "system_profile_facts"->'insights_egg_version' AS "insights_egg_version",
            "system_profile_facts"->'satellite_managed' AS "is_satellite_managed",
            "system_profile_facts"->'subscription_status' AS "subscription_status",
            "system_profile_facts"->'ansible' AS "ansible_workload",
            "system_profile_facts"->'mssql' AS "mssql_workload",
            "system_profile_facts"->'sap' AS "sap_workload",
            "system_profile_facts"->'rhc_client_id' AS "rhc_client_id"
          FROM "hosts"
parameters:
- name: LOG_LEVEL
  value: INFO

- name: CPU_REQUEST_SERVICE
  value: 250m
- name: CPU_LIMIT_SERVICE
  value: 500m
- name: MEMORY_REQUEST_SERVICE
  value: 256Mi
- name: MEMORY_LIMIT_SERVICE
  value: 512Mi

- name: CPU_REQUEST_MQ_PMIN
  value: 250m
- name: CPU_LIMIT_MQ_PMIN
  value: 500m
- name: MEMORY_REQUEST_MQ_PMIN
  value: 256Mi
- name: MEMORY_LIMIT_MQ_PMIN
  value: 512Mi

- name: CPU_REQUEST_MQ_P1
  value: 250m
- name: CPU_LIMIT_MQ_P1
  value: 500m
- name: MEMORY_REQUEST_MQ_P1
  value: 256Mi
- name: MEMORY_LIMIT_MQ_P1
  value: 512Mi

- name: CPU_REQUEST_MQ_SP
  value: 250m
- name: CPU_LIMIT_MQ_SP
  value: 500m
- name: MEMORY_REQUEST_MQ_SP
  value: 256Mi
- name: MEMORY_LIMIT_MQ_SP
  value: 512Mi

- name: CPU_REQUEST_REAPER
  value: 250m
- name: CPU_LIMIT_REAPER
  value: 500m
- name: MEMORY_REQUEST_REAPER
  value: 256Mi
- name: MEMORY_LIMIT_REAPER
  value: 512Mi

- name: CPU_REQUEST_SP_VALIDATOR
  value: 250m
- name: CPU_LIMIT_SP_VALIDATOR
  value: 500m
- name: MEMORY_REQUEST_SP_VALIDATOR
  value: 256Mi
- name: MEMORY_LIMIT_SP_VALIDATOR
  value: 512Mi

- name: CPU_REQUEST_PENDO_SYNCHER
  value: 250m
- name: CPU_LIMIT_PENDO_SYNCHER
  value: 500m
- name: MEMORY_REQUEST_PENDO_SYNCHER
  value: 256Mi
- name: MEMORY_LIMIT_PENDO_SYNCHER
  value: 512Mi

- name: CPU_REQUEST_SYNCHRONIZER
  value: 250m
- name: CPU_LIMIT_SYNCHRONIZER
  value: 500m
- name: MEMORY_REQUEST_SYNCHRONIZER
  value: 256Mi
- name: MEMORY_LIMIT_SYNCHRONIZER
  value: 512Mi

- name: CPU_REQUEST_PG_REPACK
  value: 250m
- name: CPU_LIMIT_PG_REPACK
  value: 500m
- name: MEMORY_REQUEST_PG_REPACK
  value: 256Mi
- name: MEMORY_LIMIT_PG_REPACK
  value: 512Mi

- description: Replica count for p1 consumer
  name: REPLICAS_P1
  value: "5"
- description: Replica count for pmin consumer
  name: REPLICAS_PMIN
  value: "3"
- description: Replica count for sp consumer
  name: REPLICAS_SP
  value: "2"
- description: Replica count for webservice
  name: REPLICAS_SVC
  value: "10"
- description: Image tag
  name: IMAGE_TAG
  required: true
- description: Image NAME
  name: IMAGE
  required: true
  value: quay.io/cloudservices/insights-inventory
- description: pg_repack image name
  name: PG_REPACK_IMAGE
  required: true
  value: quay.io/cloudservices/insights-inventory-pg-repack
- description : ClowdEnvironment name
  name: ENV_NAME
  value: stage
- name: APP_NAME
  value: inventory
- description: ClowdApp name
  name: CLOWDAPP_NAME
  value: host-inventory
- description: Database name
  name: DB_NAME
  value: host-inventory
- name: PATH_PREFIX
  value: api
- name: URLLIB3_LOG_LEVEL
  value: WARNING
- name: XJOIN_SEARCH_HOST
  value: localhost
- name: XJOIN_SEARCH_PORT
  value: '4000'
- description: SSL validation mode for the DB
  name: INVENTORY_DB_SSL_MODE
  value: prefer
- description: disable RBAC middleware
  name: BYPASS_RBAC
  value: 'false'
- description: disable account-to-org_id translation, defaulting to None where org_id is not provided
  name: BYPASS_TENANT_TRANSLATION
  value: 'false'
- name: KAFKA_PRODUCER_ACKS
  value: '1'
- name: KAFKA_PRODUCER_RETRIES
  value: '0'
- name: KAFKA_PRODUCER_RETRY_BACKOFF_MS
  value: '100'
- name: KAFKA_HOST_INGRESS_TOPIC
  description: The topic containing Host data sent by reporters
  value: platform.inventory.host-ingress
- name: KAFKA_HOST_INGRESS_P1_TOPIC
  description: The TOP-PRIORITY topic containing Host data sent by reporters
  value: platform.inventory.host-ingress-p1
- name: KAFKA_EVENT_TOPIC
  description: The topic for Host data that were processed by Inventory
  value: platform.inventory.events
- name: KAFKA_NOTIFICATION_TOPIC
  description: The topic containing messages to be sent as notifications
  value: platform.notifications.ingress
- name: KAFKA_ADDITIONAL_VALIDATION_TOPIC
  description: Used by system_profile_validator
  value: platform.inventory.host-ingress-p1
- name: KAFKA_SYSTEM_PROFILE_TOPIC
  description: The topic containing Host data for System Profile updates
  value: platform.inventory.system-profile
- name: KAFKA_HOST_INGRESS_GROUP
  description: The Kafka consumer group name
  value: inventory-mq
- name: KAFKA_SECURITY_PROTOCOL
  description: The Kafka Security Protocol
  value: PLAINTEXT
- name: KAFKA_SASL_MECHANISM
  value: 'PLAIN'
- name: PROMETHEUS_PUSHGATEWAY
  value: 'localhost:9091'
- name: KAFKA_BOOTSTRAP_HOST
  value: 'localhost'
- name: KAFKA_BOOTSTRAP_PORT
  value: '29092'
- name: INVENTORY_DB_SSL_CERT
  value: ''
- name: PENDO_SYNCHER_SUSPEND
  value: 'true'
- name: PENDO_CRON_SCHEDULE
  value: '@daily'
- name: PENDO_SYNC_ACTIVE
  value: 'false'
- name: SP_VALIDATOR_SUSPEND
  value: 'true'
- name: REAPER_SUSPEND
  value: 'true'
- name: PG_REPACK_SUSPEND
  value: 'false'
- name: PG_REPACK_SCHEDULE
  value: '* * * * 10'
- name: KAFKA_SP_VALIDATOR_MAX_MESSAGES
  value: '10000'
- name: TENANT_TRANSLATOR_HOST
  value: 'gateway.3scale-dev.svc.cluster.local'
- name: TENANT_TRANSLATOR_PORT
  value: '8892'
- name: GUNICORN_WORKERS
  value: '4'
- name: GUNICORN_THREADS
  value: '8'
- name: GUNICORN_REQUEST_FIELD_LIMIT
  value: '16380'
- name: GUNICORN_REQUEST_LINE_LIMIT
  value: '8190'
- name: SCRIPT_CHUNK_SIZE
  value: '500'
- name: REBUILD_EVENTS_TIME_LIMIT
  value: '3600'

# Feature flags
- description: Unleash secret name
  name: UNLEASH_SECRET_NAME
  value: bypass
- description: Unleash API url
  name: UNLEASH_URL
- description: disable Unleash (feature flags), defaulting to fallback values
  name: BYPASS_UNLEASH
  value: 'false'

#floorist
- name: FLOORIST_SUSPEND
  description: Disable Floorist cronjob execution
  required: true
  value: 'true'
- description: bucket secret name
  name: FLOORIST_BUCKET_SECRET_NAME
  required: true
  value: dummy-secret
- name: FLOORIST_LOGLEVEL
  description: Floorist loglevel config
  value: 'INFO'
- name: FLOORIST_DB_SECRET_NAME
  description: database secret name
  value: host-inventory-db
